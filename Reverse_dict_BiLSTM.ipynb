{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reverse_dict_BiLSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashinshanly/Multi-Sense-BiLSTM-with-POS-Tagger-Channel/blob/main/Reverse_dict_BiLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIh9t2-V0neH",
        "outputId": "ff19a687-ff6b-4020-f52e-62e6b1af7210"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObpCd5rZ953n"
      },
      "source": [
        "from collections import Counter, OrderedDict\n",
        "import numpy as np\n",
        "import string\n",
        "import re\n",
        "import tensorflow\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout, Embedding\n",
        "from tensorflow.keras.layers import LSTM, Bidirectional\n",
        "from keras.layers import GRU,Input\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import matplotlib.pyplot as plt\n",
        "from ms_embedding import MSEmbedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QG_KvMaqDJvc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "005d95fe-aa1a-4ae9-f14f-93e7c00ae92b"
      },
      "source": [
        "def data():    \n",
        "    punc_table = str.maketrans({key: None for key in string.punctuation})\n",
        "    sentences = []\n",
        "    targets = []\n",
        "    with open('/content/drive/MyDrive/ReverseDictionary/data/dataset_final.txt', 'r') as filee:\n",
        "        for i, line in enumerate(filee):\n",
        "            words = line.strip('\\n').split('\\t')\n",
        "            word = words[0]\n",
        "            definitions = words[1].split('; ')\n",
        "            for definition in definitions:\n",
        "                definition = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", definition).replace('  ', ' ')\n",
        "                # if definition[-1] == ' ':\n",
        "                #     definition = definition[:-1]\n",
        "\n",
        "                temp_word_list = definition.translate(punc_table).lower().split(' ')\n",
        "                temp_word_list = list(filter(None, temp_word_list))\n",
        "                sentences.append(['<start>'] + temp_word_list + ['<end>'])\n",
        "                targets.append(word)\n",
        "                \n",
        "    words = [word for word_sublist in sentences for word in word_sublist] \n",
        "    inf = float('inf')\n",
        "    frequency_dict = OrderedDict({'<end>': inf, '<start>': inf})\n",
        "    words_frequency_dict = sorted(Counter(words).most_common(None), key=lambda x:x[1], reverse=True)\n",
        "    defs_frequency_dict = sorted(Counter(targets).most_common(None), key=lambda x:x[1], reverse=True)\n",
        "\n",
        "    frequency_dict.update(words_frequency_dict)\n",
        "    frequency_dict.update(defs_frequency_dict)\n",
        "    frequency_dict.move_to_end('<start>', last=False)\n",
        "\n",
        "    word2idx = OrderedDict([(item[0], i) for i,item in enumerate(frequency_dict.items())])\n",
        "    idx2word = dict(zip(word2idx.values(), word2idx.keys()))\n",
        "    \n",
        "    return sentences, targets, word2idx, idx2word\n",
        "\n",
        "def sent2idx(sentences, targets, word2idx):\n",
        "    s = []\n",
        "    for sentence in sentences:\n",
        "        s.append([word2idx[word] for word in sentence])\n",
        "    t = []\n",
        "    for word in targets:\n",
        "        t.append(word2idx[word])\n",
        "    return s, t\n",
        "\n",
        "SEQUENCE_LENGTH = 55\n",
        "BATCH_SIZE = 100\n",
        "EPOCHS = 10\n",
        "\n",
        "sentences, targets, word2idx, idx2word = data()\n",
        "sentences, targets = sent2idx(sentences, targets, word2idx)\n",
        "targets = np_utils.to_categorical(targets)\n",
        "batches = len(sentences) // BATCH_SIZE\n",
        "print('Sentences:',len(sentences))\n",
        "print('Vocab Size:',len(word2idx))\n",
        "print('Batches:',batches)\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(Embedding(input_dim = len(word2idx), output_dim = 512))\n",
        "# model.add(MSEmbedding(input_dim = len(word2idx)+1))\n",
        "# model.add(Bidirectional(LSTM(512, return_sequences = True)))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(Bidirectional(LSTM(512)))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(Dense(len(word2idx), activation='softmax'))\n",
        "\n",
        "\n",
        "inp=Input(shape=(20,))\n",
        "\n",
        "e1 = Embedding(input_dim = len(word2idx)+1, output_dim = 512, input_length = 20,mask_zero=True)(inp)\n",
        "\n",
        "m1 = MSEmbedding(input_dim = len(word2idx)+1,mask_zero=True,att_dims = 50)([e1,inp])\n",
        "d1 = Dropout(0.2)(m1)\n",
        "\n",
        "l1 = Bidirectional(LSTM(512, return_sequences = True))(d1)\n",
        "d2 = Dropout(0.2)(l1)\n",
        "\n",
        "l2 = Bidirectional(LSTM(512, return_sequences = False))(d2)\n",
        "\n",
        "d3 = Dense(len(word2idx), activation='softmax')(l2)\n",
        "\n",
        "model = Model(inputs=inp,outputs=d3)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# visualize model structure\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model, show_shapes=True, show_layer_names=False, \n",
        "                 rankdir='TB').create(prog='dot', format='svg'))\n",
        "\n",
        "filepath=\"/content/drive/MyDrive/ReverseDictionary/models/weights-improvement-Ms.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "# Use the other generator\n",
        "'''\n",
        "def generator2(inputs, targets, batch_size):\n",
        "    \n",
        "    batches = len(inputs) // batch_size\n",
        "    for i in range(batches):\n",
        "        if i == batches-1:\n",
        "            batch_inputs = pad_sequences(inputs[i*batch_size:])\n",
        "            batch_targets = targets[i*batch_size:]\n",
        "        else:\n",
        "            batch_inputs = pad_sequences(inputs[i*batch_size: (i+1)*batch_size])\n",
        "            batch_targets = targets[i*batch_size: (i+1)*batch_size]\n",
        "        yield batch_inputs, batch_targets\n",
        "'''\n",
        "\n",
        "def generator(inputs, targets, batch_size):\n",
        "    inputs = np.array(inputs)\n",
        "    perm = np.random.permutation(len(inputs))[:batch_size]\n",
        "    while True:\n",
        "        perm = np.random.permutation(len(inputs))[:batch_size]\n",
        "        batch_inputs = pad_sequences(inputs[perm])\n",
        "        batch_targets = targets[perm]\n",
        "        yield batch_inputs, batch_targets\n",
        "input_ = np.array(targets)\n",
        "# history = model.fit_generator(generator = generator(sentences, targets, BATCH_SIZE), epochs = EPOCHS, steps_per_epoch = batches, callbacks=callbacks_list)\n",
        "# ........history = model.fit(tensorflow.convert_to_tensor(pad_sequences(sentences, 20, padding='post', truncating='post')), targets,batch_size=100, epochs = EPOCHS, callbacks=callbacks_list, verbose=1, shuffle=1)\n",
        "model.save('weights.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentences: 9065\n",
            "Vocab Size: 13434\n",
            "Batches: 90\n",
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 20, 512)      6878720     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "ms_embedding (MSEmbedding)      (None, 20, 512)      20687863    embedding[0][0]                  \n",
            "                                                                 input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20, 512)      0           ms_embedding[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 20, 1024)     4198400     dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 20, 1024)     0           bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 1024)         6295552     dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 13434)        13769850    bidirectional_1[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 51,830,385\n",
            "Trainable params: 51,830,385\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeCfpLBtNQxf"
      },
      "source": [
        "# from keras.models import model_from_json\n",
        "# json_file = open('model.json', 'r')\n",
        "# loaded_model_json = json_file.read()\n",
        "# json_file.close()\n",
        "# loaded_model = model_from_json(loaded_model_json)\n",
        "# print(loaded_model)\n",
        "# history = modelPOS.fit_generator(generator = generator(sentences, targets, BATCH_SIZE), epochs = EPOCHS, steps_per_epoch = batches, callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddBu8IavugJO",
        "outputId": "e04eab5e-a072-4627-c761-544126ec7f76"
      },
      "source": [
        "def data():    \n",
        "    punc_table = str.maketrans({key: None for key in string.punctuation})\n",
        "    sentences = []\n",
        "    targets = []\n",
        "    with open('/content/drive/MyDrive/ReverseDictionary/data/dataset_final1.txt', 'r') as filee:\n",
        "        for i, line in enumerate(filee):\n",
        "            words = line.strip('\\n').split('\\t')\n",
        "            word = words[0]\n",
        "            definitions = words[1].split('; ')\n",
        "            for definition in definitions:\n",
        "                definition = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", definition).replace('  ', ' ')\n",
        "                # if definition[-1] == ' ':\n",
        "                #     definition = definition[:-1]\n",
        "\n",
        "                temp_word_list = definition.translate(punc_table).lower().split(' ')\n",
        "                temp_word_list = list(filter(None, temp_word_list))\n",
        "                sentences.append(['<start>'] + temp_word_list + ['<end>'])\n",
        "                targets.append(word)\n",
        "                \n",
        "    words = [word for word_sublist in sentences for word in word_sublist] \n",
        "    inf = float('inf')\n",
        "    frequency_dict = OrderedDict({'<end>': inf, '<start>': inf})\n",
        "    words_frequency_dict = sorted(Counter(words).most_common(None), key=lambda x:x[1], reverse=True)\n",
        "    defs_frequency_dict = sorted(Counter(targets).most_common(None), key=lambda x:x[1], reverse=True)\n",
        "\n",
        "    frequency_dict.update(words_frequency_dict)\n",
        "    frequency_dict.update(defs_frequency_dict)\n",
        "    frequency_dict.move_to_end('<start>', last=False)\n",
        "\n",
        "    word2idx = OrderedDict([(item[0], i) for i,item in enumerate(frequency_dict.items())])\n",
        "    idx2word = dict(zip(word2idx.values(), word2idx.keys()))\n",
        "    \n",
        "    return sentences, targets, word2idx, idx2word\n",
        "\n",
        "def sent2idx(sentences, targets, word2idx):\n",
        "    s = []\n",
        "    for sentence in sentences:\n",
        "        s.append([word2idx[word] for word in sentence])\n",
        "    t = []\n",
        "    for word in targets:\n",
        "        t.append(word2idx[word])\n",
        "    return s, t\n",
        "\n",
        "SEQUENCE_LENGTH = 55\n",
        "BATCH_SIZE = 100\n",
        "EPOCHS = 10\n",
        "\n",
        "sentences, targets, word2idx, idx2word = data()\n",
        "sentences, targets = sent2idx(sentences, targets, word2idx)\n",
        "targets = np_utils.to_categorical(targets)\n",
        "batches = len(sentences) // BATCH_SIZE\n",
        "print('Sentences:',len(sentences))\n",
        "print('Vocab Size:',len(word2idx))\n",
        "print('Batches:',batches)\n",
        "\n",
        "\n",
        "\n",
        "# Use the other generator\n",
        "'''\n",
        "def generator2(inputs, targets, batch_size):\n",
        "    \n",
        "    batches = len(inputs) // batch_size\n",
        "    for i in range(batches):\n",
        "        if i == batches-1:\n",
        "            batch_inputs = pad_sequences(inputs[i*batch_size:])\n",
        "            batch_targets = targets[i*batch_size:]\n",
        "        else:\n",
        "            batch_inputs = pad_sequences(inputs[i*batch_size: (i+1)*batch_size])\n",
        "            batch_targets = targets[i*batch_size: (i+1)*batch_size]\n",
        "        yield batch_inputs, batch_targets\n",
        "'''\n",
        "\n",
        "def generator(inputs, targets, batch_size):\n",
        "    inputs = np.array(inputs)\n",
        "    perm = np.random.permutation(len(inputs))[:batch_size]\n",
        "    while True:\n",
        "        perm = np.random.permutation(len(inputs))[:batch_size]\n",
        "        batch_inputs = pad_sequences(inputs[perm])\n",
        "        batch_targets = targets[perm]\n",
        "        yield batch_inputs, batch_targets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentences: 8920\n",
            "Vocab Size: 13298\n",
            "Batches: 89\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKUgwqGM1ou3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3f9391f-f4bb-4828-f8aa-54e0b01941ab"
      },
      "source": [
        "inp=Input(shape=(20,))\n",
        "\n",
        "e1 = Embedding(input_dim = len(word2idx)+1, output_dim = 512, input_length = 20,mask_zero=True)(inp)\n",
        "m1 = MSEmbedding(input_dim = len(word2idx)+1,mask_zero=True,att_dims = 50)([e1,inp])\n",
        "d1 = Dropout(0.2)(m1)\n",
        "l1 = Bidirectional(LSTM(512, return_sequences = True))(d1)\n",
        "d2 = Dropout(0.2)(l1)\n",
        "l2 = Bidirectional(LSTM(512, return_sequences = False))(d2)\n",
        "d3 = Dense(len(word2idx), activation='softmax')(l2)\n",
        "model = Model(inputs=inp,outputs=d3)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "model.summary()\n",
        "\n",
        "filepath=\"/content/drive/MyDrive/ReverseDictionary/models/weights-improvement-Ms.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "model.load_weights('/content/drive/MyDrive/ReverseDictionary/models/weights-improvement-Ms.hdf5')\n",
        "# history = model.fit(tensorflow.convert_to_tensor(pad_sequences(sentences, 20, padding='post', truncating='post')), targets,batch_size=100, epochs = 1000, callbacks=callbacks_list, verbose=1, shuffle=1)\n",
        "# model.save('weights.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 20, 512)      6809088     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "ms_embedding_1 (MSEmbedding)    (None, 20, 512)      20478967    embedding_1[0][0]                \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 20, 512)      0           ms_embedding_1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) (None, 20, 1024)     4198400     dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 20, 1024)     0           bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_3 (Bidirectional) (None, 1024)         6295552     dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 13298)        13630450    bidirectional_3[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 51,412,457\n",
            "Trainable params: 51,412,457\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_YiPWYs60sh",
        "outputId": "6aee0238-fc9b-48c4-91b3-116a2949d4cd"
      },
      "source": [
        "history = model.fit(tensorflow.convert_to_tensor(pad_sequences(sentences, 20, padding='post', truncating='post')), targets,batch_size=100, epochs = 100, callbacks=callbacks_list, verbose=1, shuffle=1) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.0870\n",
            "Epoch 00001: loss improved from inf to 0.08703, saving model to /content/drive/MyDrive/ReverseDictionary/models/weights-improvement-Ms.hdf5\n",
            "90/90 [==============================] - 32s 361ms/step - loss: 0.0870\n",
            "Epoch 2/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.0626\n",
            "Epoch 00002: loss improved from 0.08703 to 0.06261, saving model to /content/drive/MyDrive/ReverseDictionary/models/weights-improvement-Ms.hdf5\n",
            "90/90 [==============================] - 28s 314ms/step - loss: 0.0626\n",
            "Epoch 3/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.0638\n",
            "Epoch 00003: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 25s 276ms/step - loss: 0.0638\n",
            "Epoch 4/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.0714\n",
            "Epoch 00004: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 24s 262ms/step - loss: 0.0714\n",
            "Epoch 5/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.0673\n",
            "Epoch 00005: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 24s 262ms/step - loss: 0.0673\n",
            "Epoch 6/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.0773\n",
            "Epoch 00006: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 260ms/step - loss: 0.0773\n",
            "Epoch 7/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.0895\n",
            "Epoch 00007: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 260ms/step - loss: 0.0895\n",
            "Epoch 8/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.0800\n",
            "Epoch 00008: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 260ms/step - loss: 0.0800\n",
            "Epoch 9/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.0746\n",
            "Epoch 00009: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 260ms/step - loss: 0.0746\n",
            "Epoch 10/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.0647\n",
            "Epoch 00010: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 258ms/step - loss: 0.0647\n",
            "Epoch 11/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.0710\n",
            "Epoch 00011: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 252ms/step - loss: 0.0710\n",
            "Epoch 12/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.0765\n",
            "Epoch 00012: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 255ms/step - loss: 0.0765\n",
            "Epoch 13/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.0751\n",
            "Epoch 00013: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 253ms/step - loss: 0.0751\n",
            "Epoch 14/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.0700\n",
            "Epoch 00014: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 253ms/step - loss: 0.0700\n",
            "Epoch 15/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.0680\n",
            "Epoch 00015: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 253ms/step - loss: 0.0680\n",
            "Epoch 16/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.0667\n",
            "Epoch 00016: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 252ms/step - loss: 0.0667\n",
            "Epoch 17/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.0739\n",
            "Epoch 00017: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 253ms/step - loss: 0.0739\n",
            "Epoch 18/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.0785\n",
            "Epoch 00018: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 254ms/step - loss: 0.0785\n",
            "Epoch 19/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.0722\n",
            "Epoch 00019: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 254ms/step - loss: 0.0722\n",
            "Epoch 20/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.0640\n",
            "Epoch 00020: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 253ms/step - loss: 0.0640\n",
            "Epoch 21/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.0786\n",
            "Epoch 00021: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 252ms/step - loss: 0.0786\n",
            "Epoch 22/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.0839\n",
            "Epoch 00022: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 254ms/step - loss: 0.0839\n",
            "Epoch 23/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.0811\n",
            "Epoch 00023: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 255ms/step - loss: 0.0811\n",
            "Epoch 24/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.0721\n",
            "Epoch 00024: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 251ms/step - loss: 0.0721\n",
            "Epoch 25/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.0920\n",
            "Epoch 00025: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 251ms/step - loss: 0.0920\n",
            "Epoch 26/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.1020\n",
            "Epoch 00026: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 252ms/step - loss: 0.1020\n",
            "Epoch 27/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.1006\n",
            "Epoch 00027: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 254ms/step - loss: 0.1006\n",
            "Epoch 28/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.1131\n",
            "Epoch 00028: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 254ms/step - loss: 0.1131\n",
            "Epoch 29/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.1088\n",
            "Epoch 00029: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 252ms/step - loss: 0.1088\n",
            "Epoch 30/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.1114\n",
            "Epoch 00030: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 253ms/step - loss: 0.1114\n",
            "Epoch 31/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.1104\n",
            "Epoch 00031: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 255ms/step - loss: 0.1104\n",
            "Epoch 32/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.1034\n",
            "Epoch 00032: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 256ms/step - loss: 0.1034\n",
            "Epoch 33/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.1196\n",
            "Epoch 00033: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 255ms/step - loss: 0.1196\n",
            "Epoch 34/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.1581\n",
            "Epoch 00034: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 253ms/step - loss: 0.1581\n",
            "Epoch 35/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.1766\n",
            "Epoch 00035: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 255ms/step - loss: 0.1766\n",
            "Epoch 36/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.1721\n",
            "Epoch 00036: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 255ms/step - loss: 0.1721\n",
            "Epoch 37/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.1724\n",
            "Epoch 00037: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 255ms/step - loss: 0.1724\n",
            "Epoch 38/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.1771\n",
            "Epoch 00038: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 254ms/step - loss: 0.1771\n",
            "Epoch 39/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.1623\n",
            "Epoch 00039: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 256ms/step - loss: 0.1623\n",
            "Epoch 40/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.1937\n",
            "Epoch 00040: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 256ms/step - loss: 0.1937\n",
            "Epoch 41/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.2349\n",
            "Epoch 00041: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 256ms/step - loss: 0.2349\n",
            "Epoch 42/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.2521\n",
            "Epoch 00042: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 254ms/step - loss: 0.2521\n",
            "Epoch 43/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.2715\n",
            "Epoch 00043: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 254ms/step - loss: 0.2715\n",
            "Epoch 44/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.2230\n",
            "Epoch 00044: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 255ms/step - loss: 0.2230\n",
            "Epoch 45/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.2231\n",
            "Epoch 00045: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 255ms/step - loss: 0.2231\n",
            "Epoch 46/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.2641\n",
            "Epoch 00046: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 254ms/step - loss: 0.2641\n",
            "Epoch 47/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.3457\n",
            "Epoch 00047: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 254ms/step - loss: 0.3457\n",
            "Epoch 48/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.3810\n",
            "Epoch 00048: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 254ms/step - loss: 0.3810\n",
            "Epoch 49/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.4116\n",
            "Epoch 00049: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 254ms/step - loss: 0.4116\n",
            "Epoch 50/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.3692\n",
            "Epoch 00050: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 258ms/step - loss: 0.3692\n",
            "Epoch 51/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.3091\n",
            "Epoch 00051: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 254ms/step - loss: 0.3091\n",
            "Epoch 52/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.3425\n",
            "Epoch 00052: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 256ms/step - loss: 0.3425\n",
            "Epoch 53/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.3850\n",
            "Epoch 00053: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 256ms/step - loss: 0.3850\n",
            "Epoch 54/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.4744\n",
            "Epoch 00054: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 256ms/step - loss: 0.4744\n",
            "Epoch 55/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.5823\n",
            "Epoch 00055: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 256ms/step - loss: 0.5823\n",
            "Epoch 56/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.6272\n",
            "Epoch 00056: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 253ms/step - loss: 0.6272\n",
            "Epoch 57/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.6105\n",
            "Epoch 00057: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 256ms/step - loss: 0.6105\n",
            "Epoch 58/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.4008\n",
            "Epoch 00058: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 256ms/step - loss: 0.4008\n",
            "Epoch 59/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.3619\n",
            "Epoch 00059: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 256ms/step - loss: 0.3619\n",
            "Epoch 60/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.4214\n",
            "Epoch 00060: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 256ms/step - loss: 0.4214\n",
            "Epoch 61/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.5104\n",
            "Epoch 00061: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 258ms/step - loss: 0.5104\n",
            "Epoch 62/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.5313\n",
            "Epoch 00062: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 257ms/step - loss: 0.5313\n",
            "Epoch 63/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.5530\n",
            "Epoch 00063: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 260ms/step - loss: 0.5530\n",
            "Epoch 64/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.4922\n",
            "Epoch 00064: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 257ms/step - loss: 0.4922\n",
            "Epoch 65/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.5118\n",
            "Epoch 00065: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 259ms/step - loss: 0.5118\n",
            "Epoch 66/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.4952\n",
            "Epoch 00066: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 258ms/step - loss: 0.4952\n",
            "Epoch 67/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.5272\n",
            "Epoch 00067: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 259ms/step - loss: 0.5272\n",
            "Epoch 68/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.5350\n",
            "Epoch 00068: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 258ms/step - loss: 0.5350\n",
            "Epoch 69/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.5836\n",
            "Epoch 00069: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 258ms/step - loss: 0.5836\n",
            "Epoch 70/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.5675\n",
            "Epoch 00070: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 260ms/step - loss: 0.5675\n",
            "Epoch 71/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.6731\n",
            "Epoch 00071: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 257ms/step - loss: 0.6731\n",
            "Epoch 72/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.6815\n",
            "Epoch 00072: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 257ms/step - loss: 0.6815\n",
            "Epoch 73/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.5698\n",
            "Epoch 00073: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 258ms/step - loss: 0.5698\n",
            "Epoch 74/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.4939\n",
            "Epoch 00074: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 258ms/step - loss: 0.4939\n",
            "Epoch 75/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.5179\n",
            "Epoch 00075: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 258ms/step - loss: 0.5179\n",
            "Epoch 76/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.6902\n",
            "Epoch 00076: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 24s 263ms/step - loss: 0.6902\n",
            "Epoch 77/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.5645\n",
            "Epoch 00077: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 259ms/step - loss: 0.5645\n",
            "Epoch 78/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.6745\n",
            "Epoch 00078: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 259ms/step - loss: 0.6745\n",
            "Epoch 79/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.6997\n",
            "Epoch 00079: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 259ms/step - loss: 0.6997\n",
            "Epoch 80/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.6998\n",
            "Epoch 00080: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 259ms/step - loss: 0.6998\n",
            "Epoch 81/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.7888\n",
            "Epoch 00081: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 257ms/step - loss: 0.7888\n",
            "Epoch 82/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.7161\n",
            "Epoch 00082: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 257ms/step - loss: 0.7161\n",
            "Epoch 83/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.6744\n",
            "Epoch 00083: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 259ms/step - loss: 0.6744\n",
            "Epoch 84/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.7465\n",
            "Epoch 00084: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 258ms/step - loss: 0.7465\n",
            "Epoch 85/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.8018\n",
            "Epoch 00085: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 256ms/step - loss: 0.8018\n",
            "Epoch 86/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.8328\n",
            "Epoch 00086: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 257ms/step - loss: 0.8328\n",
            "Epoch 87/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.7033\n",
            "Epoch 00087: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 257ms/step - loss: 0.7033\n",
            "Epoch 88/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.6603\n",
            "Epoch 00088: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 257ms/step - loss: 0.6603\n",
            "Epoch 89/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.7984\n",
            "Epoch 00089: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 259ms/step - loss: 0.7984\n",
            "Epoch 90/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.8271\n",
            "Epoch 00090: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 259ms/step - loss: 0.8271\n",
            "Epoch 91/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.8210\n",
            "Epoch 00091: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 24s 261ms/step - loss: 0.8210\n",
            "Epoch 92/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.7778\n",
            "Epoch 00092: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 258ms/step - loss: 0.7778\n",
            "Epoch 93/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.8071\n",
            "Epoch 00093: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 24s 262ms/step - loss: 0.8071\n",
            "Epoch 94/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.8234\n",
            "Epoch 00094: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 261ms/step - loss: 0.8234\n",
            "Epoch 95/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.8271\n",
            "Epoch 00095: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 260ms/step - loss: 0.8271\n",
            "Epoch 96/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.9125\n",
            "Epoch 00096: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 24s 262ms/step - loss: 0.9125\n",
            "Epoch 97/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.7816\n",
            "Epoch 00097: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 261ms/step - loss: 0.7816\n",
            "Epoch 98/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.7251\n",
            "Epoch 00098: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 261ms/step - loss: 0.7251\n",
            "Epoch 99/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.8842\n",
            "Epoch 00099: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 24s 262ms/step - loss: 0.8842\n",
            "Epoch 100/100\n",
            "90/90 [==============================] - ETA: 0s - loss: 0.8401\n",
            "Epoch 00100: loss did not improve from 0.06261\n",
            "90/90 [==============================] - 23s 261ms/step - loss: 0.8401\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iHU78i9DN_3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "b1fbeaac-a239-4fe1-f9e6-c710d98e34d9"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "#plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myux4c_mESXi",
        "outputId": "d823b9f6-70cc-4d4b-8dc5-4c021093c591"
      },
      "source": [
        "antonym_data = open(\"/content/drive/MyDrive/ReverseDictionary/data/antonyms.txt\",\"r\")\n",
        "antonyms = {}\n",
        "for lines in antonym_data:\n",
        "    line = lines.split(\"\\t\")\n",
        "    antonyms[line[0]] = line[1].replace(\"\\n\",\"\")\n",
        "print(antonyms)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'terminal': 'final', 'tribal': 'indigenous', 'philosophical': 'composed', 'provident': 'thrifty', 'excitable': 'wild', 'unfavorable': 'unsuited', 'unstructured': 'unorganized', 'disciplinary': 'corrective', 'deaf': 'insensate', 'unrefined': 'unskilled', 'mystical': 'divine', 'geologic': 'mineral', 'immortal': 'everlasting', 'arboreal': 'treelike', 'able': 'capable', 'unlawful': 'criminal', 'indispensable': 'necessary', 'photographic': 'photo', 'pneumatic': 'mechanical', 'inconsolable': 'despondent', 'symbolic': 'metaphorical', 'historic': 'old', 'maximum': 'utmost', 'taxonomic': 'unclassified', 'endemic': 'regional', 'intentional': 'purposeful', 'funded': 'subsidized', 'uneven': 'tilted', 'invalid': 'erroneous', 'symphonic': 'harmonic', 'concise': 'exact', 'psychiatric': 'disturbed', 'digestive': 'abdominal', 'superficial': 'glib', 'representative': 'demonstrative', 'mortal': 'life-threatening', 'disadvantageous': 'harmful', 'pathological': 'minded', 'pulmonary': 'systemic', 'sensory': 'auditory', 'humble': 'submissive', 'determined': 'staunch', 'prime': 'main', 'manual': 'standard', 'normative': 'standard', 'neural': 'sensory', 'thankful': 'grateful', 'proportionate': 'sizeable', 'dimensional': 'spherical', 'untypical': 'abnormal', 'oceanic': 'nautical', 'impure': 'tainted', 'emotional': 'feeling', 'gross': 'total', 'progressive': 'liberal', 'conjunct': 'united', 'despotic': 'autocratic', 'vital': 'lively', 'unnoticed': 'hidden', 'morphological': 'changing', 'knowledgeable': 'informed', 'vague': 'fuzzy', 'civic': 'social', 'poetic': 'rhythmic', 'climatic': 'top', 'thrifty': 'resourceful', 'probable': 'expected', 'instructive': 'helpful', 'partial': 'small', 'modal': 'typical', 'unaffected': 'untouched', 'unsatisfactory': 'insufficient', 'linguistic': 'polyglot', 'cyclonic': 'rapid', 'fiscal': 'monetary', 'recoverable': 'rectifiable', 'weightless': 'airy', 'chemical': 'solute', 'unconfirmed': 'unanswered', 'psychological': 'psychiatric', 'double': 'twinned', 'biblical': 'spiritual', 'unclean': 'dirty', 'metropolitan': 'urban', 'left': 'liberal', 'English': 'side'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXk-ajcnDR03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87915f47-8c9b-4032-d8cb-8ea2f20e525c"
      },
      "source": [
        "definition = input().lower()\n",
        "#print(definition)\n",
        "words = definition.split(' ')\n",
        "stopwords = ['a','an','the','is','are']\n",
        "if(len(words)>18):\n",
        "  for x in stopwords:\n",
        "    if x in words:\n",
        "      words.remove(x)\n",
        "n = 0\n",
        "if 'antonym' in words:\n",
        "    keyword = words[len(words)-1]\n",
        "    antonym_data = open(\"/content/drive/MyDrive/ReverseDictionary/data/antonyms.txt\",\"r\")\n",
        "    antonyms = []    \n",
        "    for lines in antonym_data:\n",
        "        line = lines.split(\"\\t\")\n",
        "        if(line[0]==keyword):\n",
        "            antonyms.append(line[1].replace(\"\\n\",\"\"))\n",
        "    print(antonyms)\n",
        "    n = len(antonyms)\n",
        "idxs = []\n",
        "for word in words:\n",
        "  if word in idx2word:\n",
        "    idxs.append(word2idx[word])\n",
        "l = 18 - len(idxs)\n",
        "# print(l)\n",
        "# idxs = np.array([0] + idxs + [1]).reshape((1,len(idxs) + 2))\n",
        "idxs = np.pad(np.array([0] + idxs + [1]), (0,l), 'constant', constant_values=(0))\n",
        "# print(idxs)\n",
        "idxs = idxs.reshape((1,20)) \n",
        "prediction = model.predict(idxs, verbose=0)\n",
        "print(prediction)\n",
        "# index = np.argmax(prediction)\n",
        "ind=np.argpartition(prediction[0],-10)[-10:]\n",
        "print(ind)\n",
        "for i in ind[::-1]:\n",
        "  # meaning = idx2word[index]\n",
        "  meaning = idx2word[i]\n",
        "  print(meaning)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "when you knew a fact or to do something in the past but then without trying you lost this knowledge\n",
            "[[1.7899694e-05 1.6158327e-05 1.8346471e-05 ... 3.8358507e-05\n",
            "  9.7346247e-06 1.6236262e-06]]\n",
            "[12188 11954   661 13254 12823   335 12458 12952 10937  1230]\n",
            "press\n",
            "encroaching\n",
            "sputter\n",
            "disjoint\n",
            "party\n",
            "seriocomic\n",
            "mostra\n",
            "possession\n",
            "furred\n",
            "asterisked\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qfxV117gRKVF",
        "outputId": "dd337bf3-ff98-4381-e853-9cd6033a09eb"
      },
      "source": [
        "predictions = []\n",
        "ground_truth = []\n",
        "test = open('/content/drive/MyDrive/ReverseDictionary/data/dataset_final1.txt', 'r')\n",
        "for i, line in enumerate(test):\n",
        "    if(i==100):\n",
        "      break\n",
        "    else:\n",
        "      print(\"Testing \" + str(i) + \"/200\")\n",
        "      print(line)\n",
        "    line = line.strip('\\n').split('\\t')\n",
        "    # if(line[0] not in idx2word):\n",
        "    #   continue\n",
        "    ground_truth.append(word2idx[line[0]])\n",
        "    # print(ground_truth)\n",
        "    definition = list(set(line[1].split(' ')))\n",
        "\n",
        "    stopwords = ['a','an','the','is','are','in','of','by','at']\n",
        "    if(len(definition)>18):\n",
        "      for x in stopwords:\n",
        "        if x in definition:\n",
        "          definition.remove(x)\n",
        "    idxs = []\n",
        "    for word in definition:\n",
        "        if(word==\"\"):\n",
        "          continue\n",
        "        idxs.append(word2idx[word])\n",
        "    l = 18 - len(idxs)\n",
        "    # print(l)\n",
        "    #idxs = np.array([0] + idxs + [1]).reshape((1,len(idxs) + 2))\n",
        "    idxs = np.pad(np.array([0] + idxs + [1]), (0,l), 'constant', constant_values=(0))\n",
        "    idxs = idxs.reshape((1,20)) \n",
        "    prediction = model.predict(idxs, verbose=0)\n",
        "    ind=np.argpartition(prediction[0],-100)[-100:]\n",
        "    # print(ind)\n",
        "    for j in ind[:10:-1]:\n",
        "      print(idx2word[j],end=\"\\t\")\n",
        "    predictions.append(ind)\n",
        "    # print(predictions)\n",
        "\n",
        "A_1,A_10,A_100,med,sq = evaluate_test(ground_truth,predictions)\n",
        "print(\"Accuracy @ 1 = \"+ str(A_1))\n",
        "print(\"Accuracy @ 10 = \"+ str(A_10))\n",
        "print(\"Accuracy @ 100 = \"+ str(A_100))\n",
        "print(\"Median Prediction Rank = \"+ str(med))\n",
        "# print(\"Accuracy @ 1 = \"+ A_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing 0/200\n",
            "forget\twhen you knew a fact or to do something in the past but then without trying you lost this knowledge\n",
            "\n",
            "sandstorm\toffice\triver\tmouth\tstroke\tstraw\trile\tlimitation\tsupply\tlaugh\ttwofer\ttracks\tsprouting\troots\tpride\tkindergarten\trushes\tgreedy\tmarsala\torientated\tremember\tsympathy\tchurch\tambition\tsea\tender\thomosexualism\tpaper\tinfinitesimal\tsill\tshowstopper\tclandestine\texcess\ttransporter\tfive\tflea\tforget\thangover\tpanoply\temergent\tice\tremain\textrude\trace\tsharing\tkiosk\tgrifter\tbars\tpatient\texplain\tsound\tshrubland\ttope\ttallest\tprotect\tbird\tstepping\tstainer\tmusic\tvarnish\tknowledge\tthanks\thear\tdemeaning\taccelerating\tbb\trehabilitate\that\tsuperstar\tisland\ttulsa\tinanimate\tgripping\tunhealthiness\tenglish\toccidental\tpipes\tsavoring\tposeur\tgovernment\tdemean\treflection\tarmy\tmoved\tuh\tprints\teast\trockefeller\tcharisma\tTesting 1/200\n",
            "office\ta room in a house or building where people study or work\n",
            "\n",
            "slant\tassort\tinternet\tspiking\tpride\taudience\tvideo\troller\tstar\tdemean\tgreen\tfight\treadied\taxonal\tmonetize\tprepare\tsurgery\tcontain\tdemeaning\tclandestine\tthanks\tsmoothed\ttoast\tsyphilitic\tlongan\treduce\timpact\tpanic\tmonopoly\tperceive\tsawhorse\tangelic\tstrawberry\toffice\tlick\tpatient\treading\tdragstrip\tpoke\tfreshly\tmouse\thorizontal\telectrical\tender\tshocked\tsnowplow\tkeyword\tbioelectricity\tspotter\taltarpiece\tfive\tensure\tlake\tfrontispiece\tgunrunner\tmusic\tmentioning\tmalware\tboyfriend\tsolve\tunaccented\tfinger\tability\tmallard\tpsychology\tbell\tnapping\tlackluster\ttruly\tpyrotechnic\tsequel\tsnow\tformaldehyde\tgraben\tstroke\ttundra\tcatastrophe\ttea\tambition\tprod\tglean\tsorrowfully\tclawhammer\tceiling\tfruit\tdisc\tbanking\tturnout\tawning\tTesting 2/200\n",
            "cheap\tsomething that does not cost a lot of money\n",
            "\n",
            "keyword\thomosexuality\tregret\tremain\tgonzo\trampaging\taliment\trationed\tobserver\tattuned\tallude\tbead\tbus\tmantrap\tdiscourage\tleggy\tensure\tdamning\tvarnish\tknife\tsilver\tcheap\tfauna\tamenities\tmorgen\tducks\ttakeaway\tglass\tstereotype\tice\ttargeting\tlunch\tcomforted\tgripping\tperceive\tteachable\tunlock\trisible\tkitten\tslant\ttoast\tforesail\tboyfriend\tcolloquy\tdemean\tremodeling\thear\tbauble\tsing\tforget\tranting\tsnickers\tpostulant\tlake\tstrep\trowboat\tcontain\tnuthouse\tbullying\tdemeaning\thubbub\tconvenor\tmimetic\tfeeder\tmallard\terector\tinvest\tuh\tlevy\tbars\tay\tanimal\tcomplain\tfirearm\tmidwife\tkibitz\triver\tclown\tart\tgolf\tpyrotechnic\tsnotty\troller\treading\tfrankincense\tchurch\tsea\tpurifying\tmonotony\tTesting 3/200\n",
            "obtain\tto get or achieve something that you want\n",
            "\n",
            "airfoil\tobtain\tsolve\tproblem\tinanimate\tfeeder\tilk\trationed\tidentify\ttope\trowboat\tresort\topportunity\troots\tunprovable\tspread\taqueous\tdisc\tattacks\trightful\tremodeling\tstovepipe\toutset\ttargeting\tworm\tmap\tveracity\tchocolate\trecipe\tlust\thorizontal\tdaisy\tsnotty\tbluster\thydrophobia\tmethod\thear\trequire\tpaper\tcommensurate\textrude\tmouth\tknowledge\tfur\tperish\tkeyword\tideas\thumming\tprod\tfun\tprints\tredo\trace\tgreen\treading\tgreedy\tconceptually\tvarnish\tmonotony\tallude\toffice\tachieve\tcoloring\ttopically\tdiscover\tsind\tisland\trile\tkindergarten\tflight\tbegin\tretrofitted\trattled\tbend\tdeathblow\thangover\tsectioned\taltarpiece\tlevy\tbursting\tstainer\tvideo\tsavoring\tdemean\tmessage\tlove\tsnickers\tcontain\thudson\tTesting 4/200\n",
            "foot\tthe bottom part of the leg on which people walk\n",
            "\n",
            "pacing\takon\tmud\tlederhosen\tillusion\tmilitarize\tlabrador\tastride\tsnow\tgreedy\tlick\tsurgery\tforelock\tmeat\toccidental\tenglish\trainmaking\tbullying\tinfinitesimal\tlaryngitis\tmonotony\tpersevere\tpetrography\treadied\tinositol\tshifty\tax\tphilippines\tfoot\tqueensland\tbaths\tliterature\tsociety\tchronicle\tice\tshrewdness\tpatient\tbarring\tkenyan\tgambrel\tducks\tchurch\tfibroid\ttechnology\ttea\tperspicacity\tethylene\tethic\teast\thorizontal\texcess\tablation\tdakota\tnature\tmouth\tphytoplankton\ttableware\tcity\tantipodal\tbibliophile\tthumbed\tcastle\teffect\tgregarious\tcaller\timportant\tswag\tprotruding\tsinglet\tinternet\tscottish\tangiography\tskua\tclandestine\tvanguard\tsubtlety\tpresident\tplimsoll\tanal\tidyllic\tresorption\tthoroughgoing\toveremphasise\tsolidarity\tincremental\tkibitz\treflection\tpaleta\tsteps\tTesting 5/200\n",
            "disc\tsomething that is a circle but also flat\n",
            "\n",
            "headache\ttraverse\tobtain\tregret\trecycle\tdance\tsharing\tairfoil\tfun\treload\tcastle\tvarnish\tprepare\twashed\taliment\tmessage\tinanimate\tperish\tchocolate\tavoid\tshocked\tlove\tknife\tsequel\tlinkup\tlose\tideas\tlick\toccur\topportunity\tposeur\tender\trequire\thear\tmilitarize\thangover\tsectioned\tswimming\tresort\tpuking\tsmoothed\tsicken\tdescribe\treadied\tbb\teasement\tenjoy\tgovernment\tevaporate\tdefalcation\tchronicle\tbegetting\tgrow\tmentioning\tvideo\tgolf\tsolve\tafford\tladen\texist\telongate\tbluster\tconcreted\ttope\tassort\tstepping\tdisc\trescript\talfresco\tsupply\tknowledge\tshelve\tflea\timpact\twheel\taccelerating\tvasoactive\topera\tdiscover\tcontroller\trecommend\tmouth\tveracity\tthwack\tdaisy\tattacks\texisting\tpedestal\tasterisked\tTesting 6/200\n",
            "identify\tto decide who someone is or what something is after thinking about it\n",
            "\n",
            "childhood\tphilippines\tthwarting\tfootedness\tyear\tilk\tuser\tprobable\tpoke\taudience\tknife\tsea\tice\tcraps\tmessage\tmentioning\tillusion\tecliptic\tidentify\troots\ttheta\tspeak\tcrock\thorizontal\tseaboard\tsympathy\tmidsized\tlookalike\tblue\tluddite\teast\ttaste\tmidwife\tshun\treading\tobjector\tenter\tlick\tgrass\tpsychic\tducks\tretroactively\tplayer\taqueous\tuh\tshrillness\tinterred\tsplattering\tbird\tpurifying\triver\tcourtliness\ttranslator\trattled\tthousandth\tachieve\tremember\tlactone\tlimitation\tchemosynthesis\trevere\texchangeable\tresorption\tfoot\tbaths\tkindergarten\tcommunicate\tdisestablishment\tdegaussing\tstereotype\tinflation\tassort\trudimentary\tblather\trile\tinfallibility\tleader\tthanks\tmining\tcoughing\tdescribe\tremain\tmap\tlongshore\tliterature\tsupply\tsalem\tknowledge\tbegin\tTesting 7/200\n",
            "thanks\tthe gesture or gratitude you give after someone does something positive for you\n",
            "\n",
            "scaleless\ttopically\tjjigae\tfurry\tfun\thitchhiking\thistory\tstubby\tunderage\tunrestricted\tgrass\tsilverside\tlaguna\tlabradoodle\tpanic\tpardoned\tdemeaning\tbring\tdemagogic\tmonographic\tworshipful\tstealthy\tgray\tbasketball\tlactone\tpigweed\tsilver\trode\tdilute\temergent\teolian\teros\tbrainwashed\trattled\tlongshore\tfurred\tbluster\taccept\twood\tplankton\tsadness\teyesight\tmay\tspinel\tstickleback\twashed\tnitrobenzene\tallude\tclandestine\tremember\taboveboard\tsheet\tosteoporosis\tsubversion\tsuperinfection\tdemean\tstroke\tvideo\trampaging\tspindly\tdiscordant\tairfoil\tprobable\tceiling\tdomestication\tproteinaceous\tmimetic\tfree\tarbovirus\tskilful\tenglish\tpeculiar\tprefer\tantislavery\tpaleta\texchangeable\tpunchbowl\tdurn\tcourtliness\ttoast\tunmeasurable\tanticipation\tsympathy\tendocrine\tstubbled\thomework\treawaken\tthanks\tteachable\tTesting 8/200\n",
            "facts\tpieces of information that are true\n",
            "\n",
            "offer\thorsebox\tsalt\tkinescope\thistory\tlabrador\tpropolis\tmanaging\tcasserole\tshearwater\tchronicle\trattled\tcalendar\tgj\tsnickers\tandrogen\tbaghdad\twood\tloach\tpersevere\tlust\tjjigae\tcamera\tinterrupt\tliquify\tpoke\tari\tfacts\tgrilling\tconsolatory\tsimultaneous\tprobable\trace\tdesk\tcan\tfood\tchew\ttoppings\tglean\tranting\tsubversion\tbarbarous\tmoa\ttitillate\tdrinkable\trecipe\tnews\tfun\tinvest\ttracks\tlactone\tsqueamish\teyesight\tgenocide\tpurifying\tfibroid\tnaughtiness\thudson\tethic\tsplattering\timmigrate\trehabilitate\tabalone\tpotato\tart\tjoshua\tlonghorn\tenglish\tweek\tlumbago\teyeglasses\tay\trationed\tbead\tflathead\tfamily\tknowledge\tvideo\tknife\tseaboard\tpetrol\tmimetic\tmaintain\troadrunner\tbegin\tprotect\taccelerating\tsalami\tlove\tTesting 9/200\n",
            "follow\twhen somebody takes the same route as somebody further ahead in order to end up in the same place\n",
            "\n",
            "despicable\twashed\ttemporal\tcartier\tqueensland\tchagrin\tgreedy\trape\tsympathy\tflathead\tanal\tmud\tprevent\tstraw\tum\tprobable\tpride\tcontemptuous\toccidental\tswimming\tbaghdad\tdaunted\tdamning\tremember\tfood\tchildhood\tvideo\tgeneralized\tmelting\tlascivious\talfresco\tendurance\tshifty\tderisory\tdog\tcockeyed\tsolidarity\tzoology\tteachable\tscreen\tpeptic\tbrainwashed\tcounterintuitive\tmonet\trudimentary\tcheese\tbonemeal\tphilippines\tnitrobenzene\taldermanic\tcancer\tunmeasurable\texchangeable\tstealthy\tdiscreditable\tthoroughness\thousebound\tasean\tsupportable\tfree\tstubbled\tquay\tgregarious\tdomestication\tillegal\tablation\tbloated\tlauncher\tdaisy\tpardoned\trooms\thyperspace\tbrawny\taspirate\tacademicism\takon\tshepard\tmonopoly\tcomforted\tmay\tblather\tdemean\therpes\tstrychnine\tinfinitesimal\tdemeaning\tintangible\tclandestine\tsqueaking\tTesting 10/200\n",
            "toast\tcooked bread that is often eaten with butter for breakfast\n",
            "\n",
            "teachable\tay\tdemeaning\tkitten\tcomforted\tsprouting\tnailing\tbead\trampaging\tgray\tensure\thace\tinterrupt\tconsolatory\tmimetic\trowboat\tdispersal\tflathead\tdamning\tmallard\tpyrotechnic\trattled\tfauna\tnuthouse\tsilver\tsward\ttrichromatic\tsnooker\tremain\thumming\tveracity\tglean\tplankton\ttoast\tdiscourage\tsalt\tchronicle\troller\tlongan\tvee\tspread\tleggy\tart\tbird\tcontemporary\tchurch\tanimal\tremodeling\trimu\tflippant\tpander\tfashioning\tvariant\trathskeller\tcheap\tlackluster\tdemean\thomework\tscriptable\tpurifying\tsadness\tmonotony\tbarbarous\tstroke\tbutter\tsavoring\tnewsgathering\tlinkup\tcontain\treduce\texpect\treflection\texplain\tdurn\tgonzo\tmelting\tbend\tobserver\taliment\ttermagant\trationed\tbullying\txxx\tslant\tsequel\tjjigae\tability\tsing\tdali\tTesting 11/200\n",
            "leader\tsomebody who controls an organisation or group of people\n",
            "\n",
            "prevent\tchagrin\tfree\tum\tclandestine\ttitillate\tdemeaning\tgents\ttechnology\tdemean\tindiscriminate\tsubversion\tconjunctive\tvardenafil\tbring\ttribe\tslavish\tnature\tunclothed\thorizontal\tdisposed\tlederhosen\tshifty\tvaried\tevaluate\tmeatpacking\tbarring\tfey\timpact\tquay\tmasturbation\tswimming\tgovernment\tpride\tbrawny\tmeat\tpresently\tcynic\textrasolar\tunderage\tpresident\tbloated\tphysiologic\tgabby\tknowledge\tadventurous\ttickle\tprohibitory\twashed\tpaleta\tcartier\tmonochromatic\tdomestication\tthumbed\tax\tstealthy\tsqueaking\tpetrol\tstemless\teyesight\tmotorola\thibachi\tspindly\tpardoned\ttailcoat\tear\tpigweed\tlick\timprove\tzoology\tbus\tsmutty\takon\tdescribe\tnight\tdevelopment\tstroke\tnapping\tgregarious\tpollock\tamenities\tstubby\tsympathy\tstickleback\tmagnification\tlush\tunrestricted\trudimentary\tforget\tTesting 12/200\n",
            "knowledge\tall of the information or facts that somebody might have in their head\n",
            "\n",
            "veena\taltarpiece\tsupply\tknowledge\tisland\tshocked\tmud\tsolve\tpipes\trecipe\tinositol\tstepping\tlose\tmouth\trepel\tvaledictory\tideas\ttea\tmegacolon\tairfoil\tcache\tawning\ttope\tsympathy\tanil\tdesk\tsmoke\tprotect\tclawhammer\triver\tmessage\thomework\tunprovable\tachieve\tkindergarten\twrite\tsheet\tfive\tvarnish\talyssum\tlake\theadache\tbb\topera\thandel\trattled\tlongan\tgreedy\tstagecoach\tbaghdad\tresort\tchurch\tdance\tambiguity\tmethod\tconcreted\tfauna\ttaste\tsharing\tremember\tclandestine\toffice\taccelerating\tfeeder\tformaldehyde\texpect\tblanket\tsill\tfruit\twood\torientated\tsport\trushes\tevaporate\troller\tpoke\tinternet\tpaper\tbutter\trile\tstash\tanabolism\ttopically\tbloated\tdescribe\teast\tdaisy\tshearwater\tlick\tTesting 13/200\n",
            "explain\tto say how a complicated situation or problem works so that other people then understand it\n",
            "\n",
            "herpes\tcourtliness\tpaleta\tchew\tuntreated\tdangling\tcontinue\tpersevere\thomebrew\tilk\texcess\troadrunner\tpatient\tperspicacity\tanchovy\tremain\tmotorola\treduce\tremodeling\tendurance\tphytoplankton\tfun\tslant\tdeterministic\tethic\ttemporal\tlimestone\tablation\tcaretaker\telephant\tencroaching\tdescribe\tbulleted\trevere\twisdom\tthoroughgoing\tanil\tremittal\tpostdate\tmiscarry\tgambrel\tgrandmaster\tsprouting\trushes\tice\tstrawberry\tsadness\tkitten\tsubtlety\tclandestine\tfashioning\tnorma\ttelephone\tcommiserate\tlactone\tglass\tsalt\tnews\treceive\tspeak\tkabbalist\tgrilling\tachieve\testimate\texplain\ttoppings\tability\tcharcoal\tswag\tbaghdad\tbleak\tfoot\tmundane\tsnooker\taqueous\tlongshore\timprove\tchild\tkindergarten\tmonopoly\tproblem\tbird\tseem\thear\tlust\teffect\tmap\tlevy\tenter\tTesting 14/200\n",
            "complain\tto express disappointment or lack of satisfaction in speech or writing\n",
            "\n",
            "infinitesimal\treadied\tlh\tdemeaning\tenglish\tremain\tbioelectricity\tswimming\tcheese\tsesamoid\ttea\tcoloring\tspeaker\tshifty\tangelic\tpaddy\tseltzer\ttransfigure\tgregarious\ttheme\tillegal\tsimultaneous\tstrawberry\tsprouting\tmosquitofish\treload\tphilippines\tmethod\tthoroughness\tswag\tstepping\tstrep\tsharing\tbbl\tregret\tsubjectiveness\ttruly\tt\thangover\treferent\tshepard\tscruffy\tsociety\tbst\taccelerating\tmelting\tsympathy\tspy\tbulleted\taimless\tviolin\tgoal\tvideo\tchurch\tnitrobenzene\tgeneralized\tdefoliated\tsolidarity\tactuating\tpestilent\tcockeyed\tvioloncello\tthoroughgoing\tdefalcation\tmonotony\tdemean\tdeathblow\tgerrymander\tmoved\tdamning\tmouth\tshrewdness\tgambrel\tused\tcomforted\tcavy\tclandestine\thydrophobia\thammy\tconsolatory\trisible\tpolitics\tmimetic\tlieutenant\tisland\texternally\tcontain\tmud\tunrestricted\tTesting 15/200\n",
            "tickle\tto touch someone in sensitive parts of their body to make them laugh\n",
            "\n",
            "taste\tlactone\tprevent\tredo\tmanaging\tshearwater\tpedagogue\tattuned\tice\tcontinue\tsilverside\tsing\thorizontal\timprove\tosteoporosis\tthwack\tpunchbowl\tforget\tkindergarten\thomosexuality\tfun\tear\tprefer\tfinger\tfoot\tfulfilled\tdry\tstagecoach\tscaleless\tdisposed\thibachi\ttoast\ttickle\tlabradoodle\tglowworm\tnational\tbursting\tfur\tenslave\tunbleached\tcourtliness\tlotus\tpaleta\tlose\tarbovirus\tstealthy\tdescribe\thomebrew\tart\tclandestine\tdemeaning\tconfuse\ttitillate\tstrep\ttody\treadied\tmastiff\telectrical\tuh\tinfinitesimal\trattled\thubbub\tlake\tremodeling\tshrillness\tdemean\tremember\tmap\ttemporal\tbring\tcultivate\tnapping\tsavoring\tforesail\tindiscriminate\tfrontispiece\tevaluate\tsea\tsob\teros\tablation\tcaretaker\tunderage\tafford\trushes\trampaging\tenglish\tpoke\toccidental\tTesting 16/200\n",
            "choose\tto make a decision between more than one options or possibilities\n",
            "\n",
            "layer\tbauble\tmouth\tsalary\trecipe\tbarge\tmudbrick\tfibroid\tgripping\taccelerating\toutset\tknowledge\tkindergarten\tproblem\tmenu\tallude\tpurifying\tdeathblow\tpanoply\tclown\thistory\thorizontal\tvarnish\thomosexualism\tgreen\tilk\tensure\tcaretaker\tgoal\tisland\toffice\tpolenta\tlactone\tethic\tice\tabiding\taviator\tattacks\thydrophobia\tthousandth\tworm\tpostulant\tregret\troots\tworshipful\tgoverness\tfirearm\tsea\tlust\tmap\tender\trationed\tlake\tlose\tglass\tlonghorn\tcity\tcircles\tpanel\tbluster\taltarpiece\tnickelodeon\them\tshiv\tshowground\tsympathy\tsandstorm\tknife\tobjector\taqueous\tillusion\treordering\tchocolate\tstovepipe\tmessage\tunderstandably\tdog\tunderscore\tshrewdness\tthanks\tairfoil\tfrankincense\tcameo\tinfinitesimal\tlongshore\tsociety\toccidental\tgovernment\trightful\tTesting 17/200\n",
            "trousers\tan article of clothing that men often wear on their legs\n",
            "\n",
            "laugh\tlonghorn\tsari\ttrilobite\ttechnology\tvideo\tsurgery\tnaughtiness\tisland\tfibroid\tbarbarous\thistory\tsalary\timmigrate\tillegal\tmorgen\tfauna\tallow\tsnooker\tclown\tfollow\tprepare\tmasticate\tpaper\tcalendar\tlabrador\tpaleta\tdrinkable\tsharing\tplimsoll\tlunch\ttransporter\tafford\tlieutenant\tcommunism\tformaldehyde\tknife\tfruit\tlongitude\tflathead\tlose\tevaporate\tmastiff\tgrow\tspeak\tgolf\tetching\texist\tnailing\tenglish\tmaintain\tleader\tlactone\tcocoa\tliterature\tmap\tinterrupt\tslant\tpoke\them\tbaghdad\tchronicle\ttoast\tsms\tupgrade\tunlock\tlongan\timprove\tshelve\ttrousers\tdefoliated\tsalem\tprobable\trecycle\tkiosk\treaction\tillusion\trace\tlugnut\talarming\tcontain\tambiguity\tsmoothed\tlake\thitchhiking\tlayer\tdiscourage\twood\texpedite\tTesting 18/200\n",
            "recycle\tto take the material from something and making it into something new rather than throwing it away\n",
            "\n",
            "night\tfinback\tlactone\tlugnut\tilk\tsympathy\tsilver\tknife\tphencyclidine\ttulsa\ttheta\troots\tillusion\tcamera\tbeefburger\tetching\tchapter\tlloyd\tpostulant\tmap\tsharing\tbaths\tregret\tbus\tinterrupt\ttargeting\ttakeaway\tcaretaker\tensure\trustication\tpapa\ttemporal\tthousandth\tmarriage\tformaldehyde\tmethod\tfive\taltarpiece\tremittal\tbead\tconcreted\tsalem\tgrass\tstoner\tgripping\tkalua\tsavoring\tfeeder\tsubroutine\tnegotiation\tdispossession\tice\tseaboard\tpaper\ttruly\tbaghdad\tredo\thangover\tsound\ttranslator\tinflation\tblue\ttoast\tlingua\tstereotype\tcircles\treading\tjason\tsurgery\trationed\tkindergarten\tanil\trecipe\tspeaker\tbasketball\tfoot\tstrawberry\tj\tfrontispiece\tleader\trabble\trattled\tdakota\tcontemporary\tarrester\tanabolism\tacoustics\tchronicle\tpeninsula\tTesting 19/200\n",
            "hat\tclothing that you wear on your head\n",
            "\n",
            "ambiguity\tknife\tjjigae\tbegin\tweek\tmaintain\tgrass\tlove\tevaluate\tlose\tantislavery\tsalary\trattled\tlaugh\tgolf\tlactone\tsupply\tseem\tinterrupt\tcaretaker\trampaging\tallude\tthwack\tpurifying\tchronicle\tisland\tilk\tdownplay\tcontinue\tbauble\tthoroughgoing\tattuned\tlayer\tgreen\tmastiff\tgripping\tecliptic\tleader\tprotect\tchew\trushes\ttracks\tbegetting\tsprouting\tbask\ttechnology\trequire\treaction\tbluster\trile\tmundane\tstagecoach\tsnooker\tsulking\tpaper\tclandestine\tpoke\texpedite\tremain\tstereotype\tpedagogue\tthanks\tpostdate\tremember\tblanket\tforget\them\tspotter\timprove\tidentify\tear\tdrinkable\tloach\toutset\teyesight\tmonocyte\tcity\tlimb\tcomplain\tveracity\tvarnish\tprovided\ttrifle\tbaghdad\tfamily\trecommend\tillusion\tmilitarize\tseaboard\tTesting 20/200\n",
            "achieve\twhen you try hard to do something difficult and you manage to do it\n",
            "\n",
            "baghdad\taltarpiece\tender\trecommend\tsalem\tstraw\tmouth\tfoot\tsuperstar\tconcreted\tstomach\tachieve\tt\tthousandth\tproblem\trace\tblimp\tgreedy\trowboat\tlust\tdog\tmap\toropharynx\tbegin\tkindergarten\tpaper\tyear\tbluster\tfood\tfurred\twood\tbullying\tice\tfundraiser\tsilver\tchocolate\tinternet\tdivide\tmessage\tdisc\tcontinue\tpatent\tbars\thyperspace\thorizontal\tcircles\tflea\tbring\tcoffee\tpanoply\tilk\tclime\tretrofitted\tisland\tsociety\twisdom\tlick\tsectioned\tfamily\tmimetic\thangover\ttruly\tfive\tmethod\tsind\tfollow\tattacks\trightful\tbutter\tvideo\tleavened\tveracity\ttraverse\tprotect\tfeeder\trockefeller\tsqueaking\tlonghorn\tmotocross\tmudbrick\tkalua\trugby\ttelephone\tphilippines\tlevy\ttundra\twrite\tperestroika\thumming\tTesting 21/200\n",
            "coffee\ta hot dark brown drink like tea but made from ground beans\n",
            "\n",
            "evaporate\tsport\tpresident\tspeak\tranting\tdisc\tprotect\tclawhammer\tpanoply\tfrisk\tbling\timpact\tlinkup\treadied\tenglish\ttracks\tgregarious\tattuned\tbonefish\tkalua\tsolve\tart\tdance\tmonetize\trequire\timmigrate\tbluster\tunanimous\trudimentary\tconcreted\ttenancy\tmouth\tstubby\tornithopod\texist\tchew\tsing\tcontain\tfollow\tunlock\twrite\tdivide\tattacks\tperish\tleapfrog\tdomestication\tdefalcation\tsplattering\tcalendar\tpincushion\theadache\tstash\tlactone\troadrunner\tillegal\trunabout\tdiverting\tlove\tremember\tuntreated\tresort\tfun\tcheckered\tbus\tcavy\tinflation\tachieve\tslab\tdaisy\tbutter\tmothered\tclothing\tbaghdad\trightful\tanchovy\tmaintain\tdescribe\tgrow\texplore\tgleam\tgrandad\ttody\tremain\tjjigae\thace\tantler\trace\tspangled\tbegin\tTesting 22/200\n",
            "government\tthe group of people who together make the decisions and plans to run the country\n",
            "\n",
            "love\tdotcom\tskua\tfamily\tsind\tgormless\tswag\tremodeling\thyperpigmentation\thumic\taudience\tpatency\tmosquitofish\tlloyd\theadwind\tlust\tamaranth\tpracticable\tprovided\tgripping\tnirvana\thumming\trestricting\tilk\tsympathy\trevolt\txxx\tjobless\ttench\tbaths\tlick\taqueous\tsatanic\tcontrarian\tbring\tfruit\tnature\tphytoplankton\tpia\tdry\thear\tpacing\toropharynx\tloft\trace\tcaretaker\tlaryngitis\tuh\tpapa\tballoons\tpedestal\ttimeliness\tpliancy\tisland\tdebugging\tmundane\texpedite\texhausting\tbarbarous\tthumbed\tillusion\thudson\timpotent\tgovernment\tlip\tconfuse\tpresident\tpatient\tsemantic\tantler\thorizontal\tlose\tpander\tfavorable\tprohibitory\tcontemporary\tprints\tscuba\tice\ttruly\ttwofer\tarmy\tvertigo\tproblem\tambiguity\tpaper\tfarce\tgreedy\tbullying\tTesting 23/200\n",
            "food\tthe stuff that humans and animals eat in order to give them the energy they need to live\n",
            "\n",
            "postdate\tidentify\tremittal\tachieve\twisdom\teffect\tweek\trecapping\tcheckered\treload\tstagecoach\tsind\tisland\tdiscourage\tmilitarize\tbus\tenergize\tmarriage\tjjigae\tsnooker\tpardoned\ttemporal\tcontroller\tproblem\tbegetting\trushes\thypotonia\tdisappeared\tupgrade\tfun\tchurch\tsilver\tsea\tdemean\tknife\tfoot\thorizontal\texpect\tprotect\tdemeaning\tairfoil\tcalendar\tdescribe\tkindergarten\tfauna\trecipe\tfollow\tposeur\tmeat\tworm\trecycle\tinterrupt\tfurred\tpaper\tsociety\tfur\tnorma\thorseshoes\ttraineeship\tlevy\tmastiff\tfood\tmundane\tcircles\tclime\texcess\taunt\tbaghdad\taltarpiece\tbegin\tsplattering\them\tstartled\tshrillness\tbell\tdubiously\tregret\tcontinue\tecliptic\telephant\tbaseball\tfree\teast\tvideo\tmidwife\tbring\tmaintain\tbluster\tdangling\tTesting 24/200\n",
            "prefer\tto like one thing more than another thing\n",
            "\n",
            "mouth\tinfinitesimal\tice\treadied\tfacts\tconcreted\tgreedy\tilk\thorizontal\tt\tconfuse\tsmoothed\tdance\taqueous\tplayer\tflooded\tinflation\tswimming\tstereotype\tunlock\tmap\tmeat\toccur\tlust\talfresco\tgovernment\tairfoil\tspeaker\tidentify\tcommensurate\tunderstandably\tbus\tshrewdness\tjobless\trisible\tpiously\tsnakelike\tsubversion\taviator\tcoloring\tworm\tknowledge\tgerrymander\ttaste\tseltzer\tprints\tliterature\tunderachieve\treinterpret\trecommend\tsolidified\tknowingly\tbaghdad\taboveboard\tgoo\tillusion\tsympathy\tclothing\tphilippines\tflight\tducks\tanswerability\tpolitics\tcheap\teyesight\tdisposed\tveracity\teffect\tforget\tlake\tirritative\tgrass\tattacks\tdarkling\tgrouped\tperish\tremain\tswag\tdomesticate\tpuncturing\tkalua\tdry\tunited\telucidate\tsport\tgreen\trecycle\tregret\tsilver\tTesting 25/200\n",
            "blanket\ta flat piece of material you put on your bed or the ground for warmth or comfort\n",
            "\n",
            "maintain\teast\tlimestone\tluddite\tsubtlety\tanal\tknife\tangiography\tspeaker\tfive\tinfinitesimal\twood\trecommend\toveremphasise\tblimp\ttracks\tidyllic\tinquisitorial\tmilk\tconsolatory\tbring\trattled\tpoke\thistory\tnailing\tmasculinity\tgrass\tlick\tbaghdad\tmastiff\tvaried\tseaboard\tpumice\tmenu\tilk\tmeat\teyesight\tthwack\tillusion\tattractor\tfaunal\tconcreted\tear\tsqueaking\tender\ttechnology\textrasolar\tcrematory\tfood\tweek\tgrep\ttheta\taunt\tvideo\thypernatremia\tblanket\tpremium\tblue\tfishing\tstroke\tmouth\tjuice\timpact\tenglish\tinternet\tjason\tbeluga\tpaper\tafford\tfeedlot\tsound\tmanaging\trudimentary\tlaugh\tgoal\taccumulation\tmortgage\tdog\tdomestication\tacoustics\tchronicle\trooms\tanabolism\tcartesian\tanchovy\tecliptic\tpetrography\tabalone\texpedite\tTesting 26/200\n",
            "decide\tto choose between more than one options or possibilities\n",
            "\n",
            "goal\thomosexualism\tlust\tmap\toutset\ttea\tfrankincense\tairfoil\tisland\tunderstandably\tmessage\tpanoply\tdeathblow\tthousandth\tsandstorm\twashed\tdownplay\tunderscore\tcameo\tender\tremain\tpostulant\thorsebox\tregret\tshiv\tbutter\tslant\thistory\tablation\tensure\tmethod\tworshipful\trile\tagouti\troots\tice\tfirearm\trisible\tbauble\tinfinitesimal\tdrinkable\tlayer\terector\tattacks\trightful\tgreen\tpolenta\taqueous\tstereotype\tchronicle\tgoverness\tstovepipe\tmouth\trecipe\tproblem\teyesight\toffice\tveracity\tshrewdness\tillusion\tchurch\tambiguity\tfibroid\tlose\tvarnish\torientated\tmundane\trationed\tseaboard\tstrawberry\tcoloring\tresort\tlimb\tdog\tdakota\tremodeling\tforget\tflight\tmimetic\tpaper\tilk\tbars\them\tsound\ttargeting\tgovernment\tknife\tkeyword\topportunity\tTesting 27/200\n",
            "desk\ta flat table for working at often found in an office\n",
            "\n",
            "allude\tlloyd\tseemly\taliment\thematuria\tupgrade\tclothing\tidyllic\tnirvana\tt\tslab\tfoot\tdesk\tstepping\tjjigae\tsesamoid\tsilver\texplore\tthoroughgoing\tresort\tfauna\tremain\tangiography\tsubcutaneous\tpumice\tthumbed\tgregarious\tdiscover\tknife\tdomestication\tretrogressive\tlove\tpollock\tprefer\tsyphilitic\tvasoactive\textraterritoriality\tsuspected\tum\tveer\thorizontal\tethylene\tbask\tpinpoint\thitchhiking\tspindly\thibachi\tideas\tbonemeal\tlackluster\tterrifying\twood\thomework\tepicure\telephant\tay\tsill\tpatient\tuser\tlake\tteamwork\tslant\tfeeder\tpyrotechnic\tbird\tangelic\thumming\tchocolate\tpeptic\treferent\tmelting\tbead\tdemeaning\tbulleted\treadied\tdeboned\tmeat\tfun\tsequel\tcockeyed\tmusicianship\tvideo\tspeaker\tairs\taboveboard\tprincipality\tburry\tsward\tphilippines\tTesting 28/200\n",
            "flea\ta small insect that lives in cat fur and bites your legs\n",
            "\n",
            "arbovirus\tdotcom\tdefoliated\ttrilobite\tmorgen\tice\tknife\ttoast\ttelephone\ttrefoil\tslant\ttaste\tbead\tsalt\ttenured\tstumping\tpanel\tcheese\tweek\thumming\tmap\tvee\tflathead\tgrow\tmonocyte\tfollow\tflea\texist\telephant\thousebreaker\tantislavery\tlactone\ticebreaking\tlonghorn\tilk\tshearwater\tax\treplacement\tmimetic\treputability\tsharing\tart\tbird\tstrawberry\tpassbook\therpes\tlose\tshifty\tsari\ttechnicality\tdescribe\tdysphasia\tcouched\tdene\tbulleted\trevere\tfurred\tinvalidated\tstrep\tvideo\tinfinitesimal\tcontain\tremain\tboyfriend\tmay\tgolf\tt\tspurge\tgrilling\tfamily\tunbleached\tfoot\tay\tcrafter\tpaper\tfancy\tcommunicate\tpurifying\timmigrate\tmarsala\trudimentary\tphilippines\tcourtliness\tpostdate\tsupply\tsociety\tsidecar\tbillet\tcosmologist\tTesting 29/200\n",
            "tallest\tthe thing that is higher or taller than everything else\n",
            "\n",
            "laryngitis\ttoast\tbring\tslant\tlose\tmiscarry\thorizontal\tuntreated\tpopulace\tlevy\tscottish\tdemented\ttrichromatic\thomework\tecliptic\tsprouting\tlederhosen\tarbovirus\tsurgery\troller\tphilippines\tleggy\tsuperstar\tvideo\twood\tchurch\tcowpox\tchronicle\timprove\teyesight\tamenities\tdaisy\tpurchase\tdelisting\treadied\tsemantic\tdemeaning\tkickoff\treload\tachieve\tcoalface\tlick\tclothing\tliterature\tbullying\tbbl\tducks\trationed\tdevastation\tsmoothed\tcheese\tilk\tcontain\tfollow\texist\tremain\tnegotiation\tgregarious\tay\tlinkup\tmouth\tgerrymander\tshifty\tlongan\tpaleta\tthousandth\tmelting\treceive\textraterritoriality\ttitillate\tprobable\tastride\tdog\tcamera\tillusion\trampaging\tdemean\tcockeyed\treading\tremember\tnature\trecycle\tbus\tability\tdebugging\tprepare\tsnakelike\thudson\troadrunner\tTesting 30/200\n",
            "realize\twhen at first you not know something for sure and then suddenly you do know it\n",
            "\n",
            "kindergarten\tmonopoly\twisdom\tbars\temergent\tloanee\tshowstopper\tdownplay\troller\titu\tbonemeal\tpresbytery\tadorable\tsoppy\thubbub\tpromotion\tacoustics\trode\twashed\tfun\tsadness\ttoast\tbaghdad\ttody\thopeless\tbleak\tprotect\tpatient\tarmadillo\tsqueamish\tprotist\tstagecoach\tmetabolically\tfeeder\tcorroborated\treagent\tunanimous\tice\texisting\tstar\tpride\tdali\tpardoned\tobserver\tlake\tstubby\tinternet\tpaper\tvee\tlongshore\tquasiparticle\tjjigae\ttheta\tbrainwashed\tacademicism\tbloated\tax\tbutter\tangiography\tanabolism\tgripping\tmonotony\twatergate\tilk\tbarring\tlimb\tsalt\tkibitz\tablation\tboyfriend\tosteoporosis\tlotus\tmasturbation\thomosexuality\taltarpiece\tcontemporary\tbird\tgriffon\thomebound\tturnout\tspinel\tperestroika\tdemean\tlush\tpolenta\tsill\tlongitude\tkickoff\tgeneralized\tTesting 31/200\n",
            "meat\tthe flesh of animals that humans like to cook and eat\n",
            "\n",
            "splattering\tfollow\tsqueaking\tangiography\tsnooker\tbaghdad\tsequel\tt\treceive\tblue\tpoke\tdemeaning\tdiscover\tachieve\taltarpiece\tcheckered\tdiscourage\tweek\tveracity\tcoexist\tdemean\tattractor\tenjoy\tfoot\tworm\trushes\tpedagogue\tboyfriend\tilk\tpaper\tcircles\tupgrade\tlove\tmeat\tremodeling\tprotect\tisland\tfeeder\tfood\tidentify\thorseshoes\thudson\tconcreted\tmarriage\tlust\tcaretaker\tallude\thorizontal\tfauna\tkindergarten\tgolf\toffice\tcoffee\tlevy\trealize\timmigrate\tdownplay\tchocolate\tforget\tsill\tlose\tdisc\tmanaging\tlick\tchurch\tcontinue\tpurity\tslave\tfamily\tswag\trequire\tmonotony\tbell\tthoroughgoing\tfruit\tqueensland\tdangling\tsport\tperceive\tender\ttaste\tplankton\tfun\tpumice\tranting\tillusion\tsalem\tcalendar\tbegin\tTesting 32/200\n",
            "bring\twhen somebody carries something towards you and maybe gives it to you\n",
            "\n",
            "bring\tlingua\tperestroika\texcess\tencoding\tdubiously\tmudbrick\toffice\toropharynx\tbeluga\tkinescope\tlick\tinfinitesimal\tdivide\trafter\tbreakwater\tcontroller\tcommiserate\tpentoxifylline\tbars\tsind\tdisc\twisdom\tanode\ttwofer\tweek\tcircles\tdiscourage\tmap\taliment\tformaldehyde\tfood\texpedite\troller\texplore\tlust\tpresident\tbarring\tasean\tgreedy\tchinoiserie\tbluster\tmatthew\tsalem\tfavorable\tclime\teffect\tchocolate\tachieve\tperforator\tarmy\tcommunicate\ttackler\tshocked\trevolt\tdurn\treading\tphantom\tfinback\tsectioned\trattled\tprotect\tchurch\tcache\tkindergarten\thiker\taudience\tice\tbullying\tkalua\tthousandth\tretrofitted\tbaghdad\tblimp\ttic\tgizzard\tmessage\thyperspace\twrite\tleachate\tconcreted\theadsman\tclapper\tnight\thudson\tgripping\tsound\tpoke\tfootedness\tTesting 33/200\n",
            "opera\ta type of classical musical performance in which performers sing and act\n",
            "\n",
            "church\txxx\tbaserunner\trequire\tstroke\tqueensland\thear\tsumma\tlip\tprevent\tcontain\ttrophoblast\tregret\treflection\tflathead\tgunrunner\tperceive\tlloyd\tslave\tpatient\tmanaging\tgambrel\tluxuriousness\topera\tcity\tdhamma\tswag\tglowworm\tstrawberry\tcommencement\ttowel\thudson\trecycle\tbasketful\thardliner\tpowertrain\tcontemptuous\tgraben\texcess\tmoor\tdisposed\ttoastmaster\tprosecution\tjustifier\thair\tdakota\tgate\torientalist\tfinger\tmatthew\tnauseated\treceive\tagitator\tcaretaker\tgregarious\treplacement\tchickenshit\tknife\treductase\tbulleted\tcalendar\ttoaster\tkeyword\ttracks\tremittal\tcheese\tfingerboard\tabalone\tinfinitesimal\tjoshua\ttaste\tclandestine\tfashioning\tay\tincognito\takon\tdiscover\tchild\tbird\tpizza\tfibrinogen\tthumbed\tlimitation\ttoast\tscreen\tmouse\tsinglet\tstealthy\ttimeliness\tTesting 34/200\n",
            "clown\ta person who acts or dresses stupidly in order to make people laugh\n",
            "\n",
            "bluster\trode\tclandestine\thummer\tdivide\tquay\tattacks\trightful\tsavoring\tbarbarous\tscaleless\toccur\tunrestricted\tpagan\tuh\tunderage\tforget\teros\tabalone\treferent\ttemporal\tflighty\tart\torientated\triver\tindiscriminate\tdemagogic\tbehavior\tstroke\ttoast\tshearwater\tlake\tloanee\tsing\tkickoff\tstealthy\ttraverse\tflea\tmelting\taqueous\tdiscordant\tunanimous\tastride\thomosexuality\tpatient\teolian\tavoid\tice\tpanic\tinsufferable\tbullying\tbars\tleader\tfurry\tgreedy\tpracticably\tnational\tstubby\tfurred\tfun\tinanimate\titu\tremodeling\tkindergarten\tsupply\tshowstopper\trowboat\tindwelling\tbus\tbloated\ttaste\tfinger\tunbleached\thomosexualism\taccelerating\twashed\tstrep\tunexplainable\thistory\tmarsala\tstubble\tblanched\tsilverside\texpensive\tsmoothed\tminded\tender\ttody\trace\tTesting 35/200\n",
            "bird\tan animal with wings that flies and builds nests\n",
            "\n",
            "flea\tscreen\tsharing\tdefalcation\ttruly\tdurn\tgleam\teasement\tkisser\tkeno\tbehavior\tbird\tfreestone\tzoology\ttrifle\tinvalidated\tfrantic\tattacks\tbbl\tvardenafil\ttambura\tcontain\tberried\tshifty\tkickoff\trathskeller\tpollock\tunanimous\tshearwater\tautism\tbaccarat\tstepping\tswallowtail\tfruit\tleavened\thector\thumming\tunderage\tspindly\tpapa\tcomfortless\toverweening\tglyceryl\tstumping\tregret\tlose\tremain\tpuncturing\tslant\tserratus\tplatforms\tcavy\treferent\tabortus\tgraben\troller\thorsebox\tcache\tcomforted\tguiding\tgolf\taliment\tinsignia\tlush\tquay\tgerrymander\talarming\tboyfriend\tmelting\tbrainwashed\tclomiphene\tpedestal\texpostulation\tprotect\tleapfrog\tcheese\tstubby\tworm\tstrep\tarchie\tchild\tlonghorn\tpursuer\tdefoliated\tsulking\tarbovirus\texpedite\tdivide\tswimming\tTesting 36/200\n",
            "race\ta competition where people try to reach a place in the quickest possible time\n",
            "\n",
            "butterfat\tgambrel\tgreen\tknife\tkinescope\tsilver\timpact\twrite\tfight\tmallard\tpresident\tsouq\tphantom\tscuba\tj\tdefoliated\tclapper\tinflation\ttruly\thooking\tlongan\tchronicle\tsoiree\tmatthew\toverbridge\tidyllic\tmidsized\tpaper\tflatly\trattled\tweek\tmouse\tsupply\tsalem\trescript\tlibrary\tjoshua\tclandestine\thudson\taccelerating\thousebreaker\tdebugging\tnewman\trace\tvestry\tsurgery\tgleam\tbutter\tcamera\tprod\tfarting\tgolf\taltarpiece\tisomerase\tlactone\tlick\tcity\tperestroika\tsinglet\tlloyd\tlauncher\twashed\tfrisk\tperceive\tbulleted\troller\tstash\tpander\tsnooker\tscreen\tsolve\tsavoring\tschizoid\tbowhead\tclime\tstar\tbars\tmudbrick\tblueprint\tpedestal\tspiking\tmouth\thackneyed\tstealthy\tredo\tpapa\tpiperine\texplore\tsuperstar\tTesting 37/200\n",
            "contain\twhen something has other things inside of it\n",
            "\n",
            "foot\toverlapping\tinositol\tunderage\tdiscordant\tnavigate\ttribe\tdivinity\tthumbed\tsubtlety\tspinal\tboiler\tcollectivist\tmonographic\trisible\tstereotype\tcoordinative\tdemagogic\tstubbled\tmonochromatic\tmixology\teros\tcomforted\tnonetheless\tplankton\thitchhiking\tpurity\tdamning\tprevent\ttermagant\tstudio\tbrainwashed\torientated\tspindly\tgents\toscilloscope\tmotorola\tthousand\tslavish\tear\thorizontal\tpunters\tevaluate\twatergate\tfrontispiece\tlev\tbooting\tnitrobenzene\tdressage\tblue\txxx\tsmutty\tfauna\tmeatpacking\tdrinkable\tsesamoid\tdemeaning\tsailing\tobjectivity\tpaleta\tsympathy\tgrass\tfun\tclothing\tspeaker\tdilute\tguiding\teffect\tstubby\tbaths\tdoubled\tay\thomework\tallude\tbead\tbbl\thopeful\tsilver\tenglish\tchagrin\tamenities\teyesight\tsociety\tprefer\tsick\twood\tleggy\tmonotony\texternally\tTesting 38/200\n",
            "fishing\ta sport or pastime that involves hunting fish from the sea or rivers\n",
            "\n",
            "referent\ttruly\tspiritual\tcache\tmarry\tart\tplayer\tmelting\tfishing\trudimentary\tcommunicate\tstealthy\tnirvana\tanchovy\tcavy\topera\tcalendar\taliment\tgambrel\tinterrupt\tslab\tclomiphene\tmonocyte\tcontain\tshearwater\tlip\tcheesecake\tcrematory\tupgrade\tberried\tswimming\tt\tbegin\tattacks\tvioloncello\tbaths\ttaste\tspeller\tsinglet\tstrep\tbell\tclandestine\ttelephone\tprevent\tbobsleigh\tsind\tkinescope\trehabilitate\tflatly\tseem\tbulleted\taccelerating\tremodeling\toccidental\thousebreaker\tspurge\tweek\texpedite\tmarsala\tgleam\tbird\thear\tovate\tscuba\troadrunner\tdefoliated\tgreedy\tfollow\tformaldehyde\takon\tbullying\tanode\treceive\tcancer\tdesk\tspeaker\tstash\tmeat\tfoot\tranting\trecapping\tregret\tstrawberry\trequire\thygienically\tstumping\tax\tmantrap\tthiamin\tTesting 39/200\n",
            "enjoy\tto feel happiness or pleasure when you do an activity\n",
            "\n",
            "national\taccelerating\tremodeling\tcommerce\tclandestine\tprevent\tattacks\tperish\tbars\tstrep\thydrophobia\trationed\tdivide\tinanimate\tdefoliated\tdisjoint\tafford\thorizontal\tlose\tice\tdemean\tcultivate\trequire\tenjoy\tfur\tdog\tilk\toutstay\tshearwater\ttaste\tkindergarten\tantislavery\tgreen\tcaretaker\tspurge\tensure\tevaporate\treduce\that\tfurry\tbask\ttruly\tswimming\ttelephone\tnonpublic\tassort\tcontinue\thear\tmixture\tsorrow\tpestilent\tlayer\tattuned\tbend\tutter\tevaluate\tinterrupt\trecycle\tbluster\tcalendar\tgrilling\tsalary\tdemeaning\tunlock\tincubate\texpect\tmidwife\taccept\tconfuse\tlactone\tblather\twrite\ttwofer\tuntreated\taudience\them\tfamily\tcache\tsimultaneous\thistory\tstarfish\tlimb\tthoroughgoing\tfollow\tmap\tpurifying\trudimentary\tunbleached\tunrestricted\tTesting 40/200\n",
            "chew\tto move your mouth or jaw up and down in break up or soften food\n",
            "\n",
            "echolalia\tender\tbora\tvideo\tposeur\trickey\tcommunism\topera\tfauna\tlysis\tstumping\tdeterministic\tnapping\tregulator\tliterature\ttench\tcynic\tconcreted\tforget\tshowstopper\tdegaussing\tkisser\ttea\tflight\tphysiologic\tinfinitesimal\troller\toligarchy\ttranslator\tafford\tdrinkable\tsharing\tillustrator\tsind\ttoast\tplayer\tattacks\tnight\tarmy\tgreedy\tarcadian\tlimitation\tdry\tknowledge\tfree\tproblem\tart\taviator\tcommiserate\tmessage\tlopsidedly\tyear\tmining\tpride\tunaccented\tdance\tleader\taliment\tjustifier\tinternet\telephant\tindiscriminate\tmap\tcancer\takan\tillegal\tsport\tluddite\tfinger\trudimentary\tperestroika\tsalem\tlooper\toffice\tfingerpointing\tarrester\tlayer\treckoner\tinflation\tgem\treplacement\tcloyingly\ttopically\taudience\tdene\tresorption\taccept\tmimetic\trevere\tTesting 41/200\n",
            "art\tthe word for painting music theatre sculpture and other creative activities\n",
            "\n",
            "courtliness\tcouched\timmigrate\tbling\thudson\tsqueamish\tshearwater\twhelk\teyesight\tantler\tjjigae\tlactone\tantipodal\tmelting\tveracity\tflathead\trehabilitate\tpeeled\tcheesecake\thermeneutic\tlonghorn\tchew\tswordtail\tillegal\trudimentary\tmasticate\tpiperine\tpurifying\tsari\tsnooker\therpes\tpolluted\tsalary\tornithopod\ttoppings\tundependable\tlabrador\tremittal\tmimetic\tcasserole\tnews\troadrunner\tlauncher\tblue\tenvisioned\tplankton\tabalone\tmap\tweek\twood\tfashioning\tart\tgrunt\tswag\tbaghdad\tmoa\tmarsala\tpaper\tflippant\tjason\tpostoperative\tdurn\tkindergarten\tstickleback\tthoroughgoing\tinquisitorial\tprotect\tabsentmindedness\tuntreated\tcommunism\tlaryngitis\tgj\tbegin\tswiftlet\textraterritoriality\trace\tstrawberry\tphytoplankton\tsplattering\tphilippines\tfruit\tobjectivity\toverpowering\tangiography\tax\tbabirusa\tseem\tsinglet\tlongshore\tTesting 42/200\n",
            "regret\tthe feeling of sadness after making the wrong choice\n",
            "\n",
            "caretaker\tchapter\treload\tmoved\ttruly\tkalua\texchangeable\tsilver\tceiling\tcoyly\tsympathy\tthoroughgoing\tcheese\troad\tpresently\tfingerpointing\tfoot\tbbl\tgreen\tqueensland\tchickenshit\ttaste\tkindergarten\tbreakwater\tsupply\tsemantic\trecklessly\twind\texpedite\tdisposed\tconfuse\teast\tice\taccelerating\tunfeeling\tballoons\tunited\ttranslucent\tfurred\tbring\tosteoporosis\tbars\trode\tsurcharged\tsectioned\thangover\tfamily\tsociety\tlloyd\thyperspace\tcommunicate\tnight\tgregarious\tcoexist\tlimb\tvarnish\tfeudalism\tillusion\tdescribe\tmusic\ttwofer\tuser\tbrazier\tstomach\twimbledon\tleavened\tcheckered\ttallest\tcommerce\thorizontal\tpowertrain\tdemeaning\taudience\tarrester\tdemean\tretroactively\tbarring\tgreedy\trudimentary\tscaleless\tinability\tcontinue\tbell\tgeneralized\tloanee\tindiscriminate\tkatana\tsmoothed\tfauna\tTesting 43/200\n",
            "tea\tpopular drink made by putting leaves in hot water\n",
            "\n",
            "rhetorically\tnational\tmycologist\trudimentary\tunaccented\tmonet\tflathead\tpatient\tgabby\tzoology\tmasturbation\tsesamoid\tdrawers\tprobable\tangelic\timpact\tax\tvaledictory\ttechnology\tpresently\tagua\tvom\tpigweed\taspirate\tpackaged\thematuria\tscottish\toverlapping\tvaried\tbooting\tfreshly\tfrisk\tswimming\tsubjectiveness\thousebound\tblather\tremember\tgregarious\treadied\tshifty\tstrep\tthoroughness\tuser\tscruffy\tum\tsupportable\tflighty\tqueensland\tteachable\tknowledge\topportunity\tmonochromatic\tbarring\tirritative\tdelectable\tinfinitesimal\tclothing\tsnotty\tpestilent\taldermanic\tmotocross\tmay\tmimetic\tbird\tdaunted\tkisser\tdiscreditable\ttruly\tanswerability\tdemagogic\tbloated\tdiscordant\tidyllic\tkickoff\tendurance\tthai\tspeaker\tmusic\tplayer\thangover\tcowled\treferent\talfresco\twaco\tsport\trainmaking\tphilippines\tambulatory\tcheese\tTesting 44/200\n",
            "reduce\tto make the amount of something lower\n",
            "\n",
            "aimless\theadache\trace\tsolitary\tbonemeal\tbegin\tlake\teast\tmatthew\twood\tkindergarten\thangover\tunited\tstubby\tclandestine\tsqueamish\tbarge\treadied\thorizontal\tcounterintuitive\tinfinitesimal\tice\tunmeasurable\tdiscordant\tshearwater\torientated\tleader\tsea\tfoot\tbaghdad\tpumice\tkalua\tshrewdness\tdurn\tsimultaneous\twashed\tuser\tenglish\tcheckered\tleavened\timmigrate\tgreedy\thomework\tresorption\taqueous\tsilver\tcraft\texisting\tunrestricted\tmonotony\tt\tsound\tshifty\trestricting\tcaretaker\tmap\tfacts\tfauna\tviolin\tspecial\tillegal\tsport\tperestroika\tthoroughgoing\triver\ttaste\tsnow\trudimentary\tpuking\tear\teffect\tbb\tseltzer\tchauffeur\tdisjoint\tsequel\troadrunner\tphilippines\tthumbed\ttruly\tevaporate\trile\tsympathy\texchangeable\tpurity\tpolitics\tacoustics\tablation\tfurred\tTesting 45/200\n",
            "discover\tto find out some information or to locate a place that was not generally known beforehand\n",
            "\n",
            "improve\tphilippines\tprovided\tclandestine\tvideo\tdiscover\tfollow\tafford\tlose\tkeyword\tcausative\tremodeling\tresort\tupgrade\tbead\tmethod\tchronicle\tisland\tcastle\tremain\tstrep\timmigrate\tuser\tseem\tmud\tlake\tprotect\tproblem\tsharing\tbegin\tfeeder\tmap\tbullying\tknife\trattled\twashed\tear\tfood\tbaghdad\tinterrupt\tcommunicate\tassort\tgreedy\trudimentary\taliment\tdownplay\tconcreted\tkinescope\tmundane\tilk\tworm\tchurch\tdiscourage\tinanimate\taqueous\tice\tgonzo\tfacts\tlove\tidentify\torientated\tsawhorse\tpaper\tarmy\tdry\trushes\ttargeting\tstrawberry\tgrow\tmessage\trecipe\telongate\texplore\tlick\tducks\tlevy\tstovepipe\tdevastation\tbars\tstereotype\trationed\tmarry\tsmoke\thitchhiking\tpostulant\tchocolate\tsalem\tinterred\tposeur\tTesting 46/200\n",
            "library\ta place where many books are stored so that people can easily access them\n",
            "\n",
            "fibroid\tjjigae\tcraps\tbulleted\tfollow\tclawhammer\tsurgery\tdeathblow\tambition\tendurance\tmasturbation\tsociety\tmoved\tcathedra\taltarpiece\tschizoid\tbus\tstash\treflection\tability\tpedestal\tlawman\tresort\tlake\treload\tfauna\tleapfrog\tilk\tanchovy\tgregarious\tfur\tgleam\tcards\tkeno\tpostdate\tsupply\tthanks\trace\tantler\tlose\tfood\tmoor\tunanimous\tbluster\tvestry\tsnooker\tillegal\tmeat\texplore\tbreakwater\trequire\tfamily\tcontain\tinsignia\tproblem\tsprouting\tredo\tmarriage\tpincushion\tgau\tbenne\tenglish\toffice\tlonghorn\tpopulace\tregret\tdepend\texplain\taunt\tcircles\tmethod\tbaseball\tchinoiserie\tmonetize\tstar\tnorma\tplankton\tfashioning\tfurred\ttransfigure\twisdom\tbegin\tideas\toverweening\tsplattering\tunderage\trunabout\tvioloncello\tsport\tTesting 47/200\n",
            "expect\tto think into the future and feel that is is likely that a particular event will happen\n",
            "\n",
            "spiritual\tliterature\tdelisting\tmap\tvee\taudience\tnegotiation\ttoast\tcamera\tlugnut\treplacement\tdisc\tflea\tsprouting\tbenne\tsalem\thopeful\tay\tstrawberry\tmouth\tcache\tattacks\tlongan\tcheese\taltarpiece\tbird\tdog\tfauna\ttruly\tsnooker\tarmy\tjudicious\tensure\tgeneralized\tkindergarten\tice\thorizontal\tfeeder\thiker\thyperspace\teast\tanil\tspeaker\tfirearm\tpeninsula\thydrophobia\tlonghorn\tbars\tlloyd\tformaldehyde\tglass\treading\tbaghdad\tphilippines\tinflation\tcalendar\tmethod\ttemporal\tpresident\tredo\tshearwater\tvideo\tregret\tisland\tbell\tenglish\tsolidarity\tpromotion\tscuba\tmelting\tanimal\thudson\tceiling\tmorgen\tboyfriend\tremain\tlieutenant\twimbledon\tmosquitofish\tzoology\tsuperstar\tanimation\them\tchew\twine\tmusic\tanchovy\ttaste\tradioactively\tTesting 48/200\n",
            "year\ta period of months corresponding to the earth orbiting the sun\n",
            "\n",
            "laryngitis\tarbovirus\tdysuria\tmap\ttaste\tpresident\textraterritoriality\tillusion\tswallowtail\tcowpox\tcasserole\tpolluted\tkinescope\tallow\tfamily\tcanvasback\tprovided\tilk\tantler\tinvalidated\tlose\tshearwater\tperestroika\tvideo\tbluster\tcommunicate\tmelting\tbleak\tchew\tanil\tloach\trationed\twisdom\tunfeeling\tbring\tpanoply\tblue\tornithopod\tmoa\tflathead\tfollow\tliterature\tpolitics\tgregarious\tcontemptuous\tuntreated\tgreedy\trace\tcelibate\tmasticate\tswag\tbullying\tsind\tbbl\tcontinue\tinterrupt\tprobable\tdecide\tthousandth\thomosexuality\tremember\thumming\tthanks\tchurch\tundependable\thorizontal\tpreventive\timpotent\tfree\tcache\tbilious\tunanimous\tdomestication\tfortissimo\tprotect\tbiology\ttody\tcommunism\tvarnish\trooms\tdescribe\trudimentary\twhelk\tnews\taudience\tunenforceable\tsplattering\tlederhosen\tantislavery\tTesting 49/200\n",
            "sport\tan organised competitive activity or game where physical skill is needed\n",
            "\n",
            "elephant\trehabilitate\tscreen\tmud\ttaste\tmantrap\tflighty\tremittal\tmilestone\toccur\taspirate\tart\tmeat\triver\tproblem\tsawhorse\tsea\tmastiff\tdiocesan\tsavoring\ttoast\tposeur\tpatient\tdiscourage\ttracks\tsurcharged\tpolitics\tmonopoly\toverlapping\tdaisy\tbullying\tfoot\tblanched\topera\troller\tcalendar\tweek\tskittle\tmessage\texpect\tbaths\tflathead\tchocolate\tlyceum\treflection\tability\trace\tqueensland\tpurity\terector\tbooby\tgreedy\treceive\tcastle\tfood\tlibrary\thair\tframboise\tsurvivability\tlake\trainmaking\tpretreatment\tprotect\thace\tsport\tchurch\tbulleted\tpresently\tarmy\tslant\toccidental\tbursting\tmatthew\tstealthy\tgrep\tflight\tslab\tgonzo\teyespot\tplankton\tslave\tmilitarize\tlabrador\tfauna\tunderage\tleader\tmotocross\tablation\tbonemeal\tTesting 50/200\n",
            "blue\tthe colour of the sea or the sky\n",
            "\n",
            "illusion\tresort\teffect\tbegin\tenglish\tdeltoid\tfeedlot\tidyllic\tendocannabinoid\tlooted\tgrass\trestaurant\teast\tcraps\tfun\tlolol\texisting\tmarsala\tbonemeal\triver\tglass\tredo\tmouth\tfeeder\toutset\tt\tslab\tblueprint\tceiling\taqueous\tidentify\tskittle\thomework\tfacts\tsuspected\tmessage\tbb\trehabilitate\tdownplay\toropharynx\tkindergarten\ttulsa\tclothing\tuser\thorizontal\taboveboard\tsyphilitic\thangover\tice\tleader\tavoid\tsequel\trode\tseaboard\tgreen\tluddite\tmusic\ttwirling\tblimp\tgrandad\tcookhouse\tmansard\tsawhorse\treadied\tinterred\tsind\tchurch\tpaper\tsea\tseedbed\tprefer\tfavorable\tbus\tanil\tfunctionality\taltarpiece\tdiverting\tcoexist\tlingua\tstash\tfingerpointing\tdurn\tchauffeur\tblue\tcheckered\talgorithm\tsilver\tgonzo\thackneyed\tTesting 51/200\n",
            "poke\tto touch someone or something with an extended finger or long thin object\n",
            "\n",
            "east\tunrestricted\tunderage\tpurifying\tideational\tscaleless\toffer\tsharing\twrite\tcity\topportunity\tcaretaker\tlactone\tambulatory\taliment\tmarsala\timpoverish\tspangled\tbars\ttrilobite\tilk\tfruit\tshocked\tsalami\tremember\tweek\tsparse\talfresco\tbring\teolian\trace\tcancer\tattacks\tballoons\ttracks\twashed\tear\tfinger\tclandestine\taccelerating\tbask\tsummertime\tducks\tbluster\tleader\tillegal\tpresident\tdance\tsympathy\ttitillate\tstash\tsimultaneous\tlotus\tsilver\tleavened\tpotato\taudience\trattled\tencroaching\tendorphin\teffect\tbaths\tillusion\tdoubling\tcommunicate\tsound\tcontinue\tglass\tice\tdysuria\thyperspace\tdormitory\tsavoring\tbell\tforesail\tranting\tnirvana\tsprouting\tgripping\tsalt\tpromotion\tperestroika\tbitters\tsubversion\tproblem\tdatum\tworm\tlust\tmessage\tTesting 52/200\n",
            "strawberry\ta sweet red fruit often eaten with cream\n",
            "\n",
            "dragstrip\tvideo\tnews\tdurn\tuntreated\tdemean\tkeyword\tperspicacity\trooms\tdemented\ttoast\tschizoid\tegomania\tcoreopsis\tbulleted\tsind\tvarnish\tcosine\tart\ttackler\tay\tgonzo\tsalt\tbst\tsnow\tfun\tnuthouse\tdenaturant\tmalware\tcache\tdemeaning\tbarring\tbutter\tmallard\tmethod\tmouse\tbbl\tisland\tfauna\tdakota\tuh\tpolitics\tice\tcheese\tinsufferable\tthoroughgoing\tfood\tdebugging\tlip\tstrawberry\tregulator\tmonetize\tnailing\tchurch\tmoved\tfirearm\tremittal\tich\tlh\tclandestine\troller\tillegal\torientalist\tbullying\tveracity\topera\tinterrupt\tnirvana\trickey\tmentioning\tmonotony\tcamera\tacademicism\tsnooker\ttea\tkinescope\tprosecution\tdisc\tcrossbill\tproblem\taudience\tlauncher\tsward\tmatthew\tthrush\tcaller\tbonefish\tmarsala\tsubcutaneous\tTesting 53/200\n",
            "avoid\tto make sure that you do not come close to somebody or something\n",
            "\n",
            "remodeling\timpotent\tdaisy\thumming\tliquidity\tinfinitesimal\tforget\tstealthy\tfur\tlake\tendurance\tcultivate\texplore\tkindergarten\toccur\tstovepipe\teec\tconcreted\tdivide\tdiscourage\terector\tgolf\thorizontal\tmethod\tgreedy\troller\tability\tlick\tfurred\tlust\tgleam\tbird\tstubby\tbullying\tfeeder\tmundane\tachieve\tfollow\tbegin\tsequel\tsqueaking\tsociety\trightful\tcontain\tsectioned\tbilious\tsupply\taliment\tprepare\tt\tstartled\tflighty\tattacks\tranting\tairfoil\tdefalcation\tvioloncello\tmouth\tshelve\tshocked\toffice\tcommiserate\taltarpiece\tbell\twashed\timprove\tbluster\tbursting\tprints\tdemeaning\tdance\tspeak\thear\tworm\tpatient\texcess\tshun\trowboat\trestricting\tdisc\tphilippines\tdepend\tshifty\tallude\tdemean\tcounterintuitive\treward\tchocolate\tfood\tTesting 54/200\n",
            "washed\tsomething that has been cleaned with water recently\n",
            "\n",
            "linkup\tarchie\tprod\tdance\taltarpiece\tbulleted\tambition\tsnowplow\tfun\tsynopsis\twashed\tvaried\tvardenafil\tpetrol\tunanimous\ttope\tfrisk\tfur\ttwirling\tbluster\tkanga\tagua\tsicken\tlauncher\tslab\texplore\tflight\tsport\tcontain\tsavoring\tspeller\tdesk\tpincushion\tblanched\tdeathblow\tmoor\tforget\tlip\tpedestal\tlibrary\tresort\tgleam\ttaste\tbring\trace\tballoons\texpostulation\tnapping\thighlighter\tcircles\tstrep\tswimming\tprosecution\tbarring\tstar\taccelerating\tdelectable\tobtain\tspeak\tsubcutaneous\tfurred\tsupply\tchinoiserie\tability\toverlapping\trainmaking\tstraw\tsoiree\tbenne\tdefalcation\tcity\tfruit\tcavy\tpresident\tstash\tkiosk\tredo\tsharing\tlust\tbobsleigh\timpact\tthwack\tsplattering\ttitillate\tenglish\tregret\tbribe\tlush\thousebreaker\tTesting 55/200\n",
            "ice\tfrozen water that you can put in your drink to make it colder\n",
            "\n",
            "underage\tbaths\tfoot\tpoke\tsupply\ttrifle\thitchhiking\tstubby\treceive\tattuned\tcheese\ttaste\tlagoon\tsob\tproblem\tpaper\tavoid\tice\tmanaging\tsesamoid\tart\tlotus\tangelic\tplankton\twrite\tfreestone\tlose\tear\tlaguna\tmansard\tdance\tgrass\tattacks\tdeathblow\tdescribe\tkindergarten\tfrankincense\tshowstopper\tregret\tblanket\tmay\tarbovirus\tremain\tmastiff\tremember\tsharing\tstraw\tbring\tilk\tremodeling\tpatient\tkiosk\teros\tsea\telephant\trealize\tbulleted\tloach\tpostdate\trile\tglass\tenglish\trushes\tcomforted\tinfinitesimal\treadied\tfashioning\tsqueaking\ttea\tfulfilled\tprotect\tcontinue\tgraben\ttoast\ttrilobite\tknife\twashed\tmonotony\tflea\tsympathy\tbegin\ttody\tethic\tawning\tafford\tdog\tbus\tpride\tcommunicate\tTesting 56/200\n",
            "mud\tdirty wet brown earth found on the ground after it has rained\n",
            "\n",
            "checkered\tsmoke\tdownplay\tpatient\tremittal\tmud\tconcreted\treadied\tchocolate\tstagecoach\tbaghdad\tmouth\tmessage\tantipodal\tstubby\tendurance\tlinkup\tpincushion\tillegal\tillusion\tbell\tuser\tyear\troller\tpaper\tdescribe\tanabolism\tresort\tsind\tblanket\tupgrade\tmarsala\tdaisy\tmarquise\terector\tcrock\tfauna\tbarring\tprotect\tmonopoly\tsplattering\trudimentary\treload\tsuperstar\tpestilent\tlonghorn\tmotocross\tnorma\tbars\tfun\tbluster\tthoroughgoing\tplayer\tmethod\tseltzer\tsalem\tmastiff\tobserver\tdonut\tkalua\tdiverting\tbaseball\tcraps\tstipulation\tfood\tdemented\troadrunner\taltarpiece\tvideo\tambition\tgreedy\tclime\tclothing\texisting\tcastle\tchronicle\tmaintain\tflighty\telephant\tablation\tlove\tcheesecake\tattractor\tbiotite\tsnooker\titu\tstar\tt\teffect\tTesting 57/200\n",
            "continue\tto keep doing something when stopping was a possibility\n",
            "\n",
            "kalua\tremittal\tpardoned\tluddite\tproblem\tpaper\tender\tisland\tperestroika\teffect\tbus\trecycle\tchronicle\tcommunicate\timmigrate\tassort\tmimetic\tthoroughgoing\tmessage\troots\tfauna\treceive\tplayer\tmansard\tbonemeal\tpapa\tshun\tchurch\tchildhood\taunt\treload\tsmoke\tfavorable\tbegin\taqueous\tworm\tfamily\texisting\tinability\tcontinue\tecliptic\tbars\tbloated\tdisestablishment\tlimb\tsind\tvideo\tanil\tregret\topera\tuser\tdemean\tillusion\tkinescope\troad\tclime\taltarpiece\tlevy\toutstay\tarrester\tcoexist\tspangled\tcheckered\tsound\thistory\toffering\tfowl\tseedbed\tpoke\tinterrupt\tfight\tgreedy\them\tjason\tcontemporary\tblimp\tmarriage\tdescribe\tbluster\tknowledge\terector\tmarsala\toverbridge\thorsebox\tdegaussing\tenergize\textraterritoriality\trightful\tskittle\tTesting 58/200\n",
            "internet\tthe network connecting computers in the world and allowing information to be shared\n",
            "\n",
            "rattled\thair\temergent\tdevelopment\ttelephone\tcommunicate\tforget\texplain\tbooby\tinternet\texpect\tnight\texhausting\tluddite\tbutter\tbarring\trudimentary\tmouth\tcowtown\tsharing\tvee\tfinger\tmessage\tarrester\tart\tlactone\tflight\ttea\tbars\treading\tdaisy\tabortus\tfreestone\tfun\topera\tunanimous\tdysphasia\tsill\tisomerization\tbounded\taccumulation\tremember\tsynopsis\troots\tpincushion\tgyroscope\tnonchalantly\teast\tinfallibility\tjoshua\tcourtliness\tsport\tcontemporary\tqueensland\tskittle\tvarnish\tsorrowfully\tmotocross\tslave\thorsebox\twimbledon\tlysis\tmasculinity\tbloated\thace\torchard\tpapa\tillustrator\tmantrap\tvom\tpride\teyespot\techolalia\tbead\ttransporter\taunt\tincognito\tfree\tsplattering\trecapping\trile\tnorma\tanimation\tcomforted\tlooper\treflection\tdemean\tpotato\tenter\tTesting 59/200\n",
            "reading\tthe activity of looking at words or text and understanding what they mean\n",
            "\n",
            "toast\tgormless\tchurch\tbenne\tum\tinanimate\tgreedy\tisomerase\triver\tillustrator\tantler\tfulfilled\tbird\trationed\tbars\tpatient\tstagecoach\tlongan\tshun\ttranslator\tsharing\tfamily\ttaste\troller\ttruly\tbring\tlunch\tlookalike\tsympathy\tdemeaning\taccelerating\tbreakwater\treadied\texchangeable\tfree\tpolluted\tplimsoll\tpardoned\tgeneralized\tilk\tpanoply\tstomach\tcommerce\tstealthy\tbrazier\tdemean\tsavoring\ttheta\tprotect\tillusion\tarmy\tevaporate\tcowpox\tcommunicate\tmoved\tillegal\tpresently\tmentioning\tavoid\trattled\tachieve\thubbub\tremember\tice\taltarpiece\tflathead\tinternet\tgreen\tcontain\tmalware\tunanimous\tgleam\tfight\tlake\tdivide\tthanks\tbrawny\tensure\techolalia\tmusic\tfarting\tarrester\ttope\tstarfish\tdemented\tswallowtail\tgregarious\tsemantic\taudience\tTesting 60/200\n",
            "method\ta particular way of doing something\n",
            "\n",
            "marsala\tchurch\tbaghdad\tsuspected\trockefeller\tunited\twisdom\tdaisy\tagua\tinanimate\tdysuria\ttope\tunderage\tfavorable\texplore\thumming\tfarting\tmelting\tattacks\tcommerce\tstubby\thomework\tensure\texchangeable\tkindergarten\trightful\tbullying\tbluster\torientated\tceiling\tmutual\tthousandth\tspeaker\tsadness\treflection\trowboat\tcowled\ttruly\trile\tcomplain\tmethod\ttallest\ttranslator\thowell\tsequel\tgoal\thangover\trode\thomosexuality\tstroke\tshearwater\tpracticably\tvee\twashed\tsolitary\tbars\tdurn\tcheap\tveracity\tblimp\tay\tdemean\tbbl\tunroofed\tperestroika\tmatthew\tdemeaning\taccelerating\tbursting\titu\tleggy\tgrass\texisting\tlake\tpanoply\twood\tmacdonald\tsind\tglass\thubbub\tsociety\tt\trudimentary\tcommensurate\tmoved\tfurred\tdeathblow\tdomestication\taimless\tTesting 61/200\n",
            "ability\tthe skills that somebody has\n",
            "\n",
            "linkup\tpursuer\tflight\tdefalcation\tpedestal\tdurn\ttambura\tstash\tconformism\tnaturopath\tpapa\tantler\tcoexist\tarbovirus\tlip\tvaried\tecumenical\tcathedra\tcavy\tlush\tfood\tbluster\ttainted\tbobsleigh\tgleam\treadied\tsectioned\ttruly\tgraben\ttg\tswallowtail\tpinpoint\thangover\tfruit\tsplattering\tlonghorn\texplain\ttitillate\tresort\tcache\tpincushion\taquamarine\tdemean\tvioloncello\tgregarious\thumming\tability\tlust\tchinoiserie\tkalua\tlibrary\tsequel\tfibroid\tremittal\tclothing\tregret\tdemeaning\trace\tgerrymander\tidyllic\timpact\tballoons\tpiperine\taviator\tpresident\tbring\tstrep\tsharing\tfollow\tseedbed\trefreshing\tmouth\tenglish\tdisappeared\tpestilent\tuser\thector\tstainer\tclawhammer\trecycle\tpuncturing\tglyceryl\texisting\tsynopsis\tcoloring\taccelerating\tserotonin\taunt\tunanimous\tTesting 62/200\n",
            "nature\tall of the living things in the world\n",
            "\n",
            "salary\tbbl\takon\tsociety\tcheese\tremain\tjason\tnature\tmidcourse\tclothing\tuntreated\tfoot\tdodgy\tprogramming\tpaleta\tpresently\tstubbled\taqueous\tlose\tlaryngitis\teyesight\tunited\tliterature\ttaste\tbus\tspinal\torientated\tfamily\tsojourn\tsimultaneous\tamenities\tthoroughgoing\tbaghdad\timmigrate\tshrewdness\tmap\tice\tswiftlet\tadventurous\tthousandth\tsmutty\tmosquitofish\tsolidarity\tphilippines\tgovernment\tisland\tgrass\tzoology\tknife\tdisposed\tambiguity\tmouth\ttribe\tabsentmindedness\tsodomize\tlascivious\telephant\tsympathy\thorizontal\tastride\tantislavery\tthoroughness\trisible\tswag\tcontemptuous\tpurifying\tprovided\tbird\ttoast\tunderage\tobjectivity\tilk\tdefoliated\tpolitics\tfollow\tirritative\tsnakelike\tchildhood\tspeaker\tleggy\tay\tflooded\tdog\texist\tpacing\tperspicacity\tplankton\taccelerating\thistory\tTesting 63/200\n",
            "night\tthe time at the end of the day when the sun goes down and people sleep\n",
            "\n",
            "greedy\tchurch\tsnooker\tsnow\tfollow\tgraben\tprotect\tunited\tillegal\tcowpox\tsolidarity\tkabbalah\tgizzard\ttoast\tthanks\tmoved\twisdom\textrasolar\tsympathy\tnight\tbird\tpresently\tbilious\tpresident\tacademicism\tglass\tencroaching\tsalem\ttrifle\tforever\ttrilobite\tsemantic\tleasehold\tmarsala\toropharynx\tcynic\tcommunicate\tillusion\tbaghdad\tfamily\thorizontal\tambiguity\thyperspace\tbring\tthoroughgoing\tuser\texisting\tthousandth\tlick\tdurn\tsociety\timpotent\taudience\tliterature\ttahini\tchapter\tgregarious\tlust\tdog\thousebound\tstomach\ttimeliness\tcommunism\tarbovirus\tdespicable\tice\tpardoned\tfood\tecliptic\tperestroika\textraterritoriality\tyear\tcontemptuous\tclime\tpaper\tbell\tmastiff\texcess\tvideo\tdakota\tbleak\teffect\tballoons\tfruit\tpeeled\trushes\tpestilent\tarmy\tnegotiation\tTesting 64/200\n",
            "communicate\tto share ideas or knowledge with other people using language or signs\n",
            "\n",
            "demean\tshocked\treadied\tdemeaning\tclandestine\tgreen\tpaddy\tpacing\tspecial\tcheese\tfinger\tlayer\tdrinkable\tdry\tfulfilled\teast\tsurgery\tsport\tillustrator\tsomber\tnoncombustible\takon\tvarnish\tmentioning\tchronicle\trace\tarmy\trile\tmonochromatic\tvaried\tlimb\ttranslucent\tsharing\tbst\tgregarious\tchurch\tqueensland\taspirate\tnewman\tliterature\tillegal\tprovided\troots\tagouti\tperestroika\tgoo\tsynopsis\tmethod\tsympathy\tinfinitesimal\tgreedy\tunrestricted\tfruit\tsimultaneous\tknowledge\tstash\tmalware\tindiscriminate\treinterpret\tcommunicate\tstroke\tswag\tpoke\tbloated\tshifty\trattled\ttea\tcontemptuous\tseltzer\tskua\tsilver\tfree\ttrilobite\tsmoothed\ttruly\trooms\tanal\tcraft\tdakota\thopeful\tsea\tisomerase\texpedite\tlloyd\tdisposed\tisland\topportunity\tdescribe\tpatient\tTesting 65/200\n",
            "greedy\ta way to describe somebody who wants lots and lots of food or money\n",
            "\n",
            "swag\ttallest\tgoal\tvom\tinanimate\tpolluted\twisdom\tdemean\trudimentary\treadied\twood\tbird\tendurance\tpapa\texisting\treflection\ttranslucent\tegomania\tinquisitorial\tmentioning\tcoughing\tprotect\tbbl\tpagan\timpotent\tproximate\tperestroika\tsidecar\tability\tcowled\tcache\tundependable\tdomestication\tgregarious\tmasthead\tfood\tknowledge\tswallowtail\ttruly\tenvisioned\ttableware\tdiscourage\tbonefish\tgreedy\tsequel\therpes\treload\texternally\tsparse\tdurn\tremittal\tbilious\tlongshore\ttuberculous\thomework\ttasty\titu\tachieve\tmarry\tdemeaning\tantler\tconcreted\ttonal\tmasticate\tdemented\tpatient\tfaceted\tstomach\tstealthy\tfree\tdakota\temergent\tattacks\tcowpox\tbrawny\tbristled\tdysuria\tavoid\tunobstructed\tcoyly\tbullying\tcheese\tilk\troadrunner\tdivide\tcoexist\tpestilent\tlackluster\tslab\tTesting 66/200\n",
            "paper\ta material that is normally white made from trees and useful for writing on\n",
            "\n",
            "jjigae\tstroke\tilk\toffer\tpolitics\tconcreted\tnews\tdiscover\ttracks\tambiguity\tbarbarous\tmosquitofish\troots\tsnooker\tmarriage\trattled\tspread\tlayer\tdebugging\tdesk\tisomerase\thistory\texist\tlick\tweek\thear\tlongan\tcommencement\tspangled\templacement\textraterritoriality\tspiking\tmap\tbarring\tkeyword\tbegin\tliterature\tcontemporary\tknife\tcomforted\tcalendar\tlinkup\tsnowplow\tpatency\tfollow\tandrogen\tprovided\ttargeting\thudson\ttowel\tlose\tmelting\tsurgery\tvideo\tchronicle\tmouth\timmigrate\ttoppings\tecliptic\tmonocyte\teyesight\timpact\tdelisting\twhelk\tprotect\tisland\tpander\tforelock\tafford\tstovepipe\tagouti\tjason\tclandestine\tvariant\tsolve\tbaghdad\ttoast\tangiography\tpaper\tvestry\tay\tinflation\tdisc\tlove\tpiperine\tkinescope\texpect\tnewsgathering\treload\tTesting 67/200\n",
            "snooker\ta sport played on a green table with balls of different colours\n",
            "\n",
            "aurochs\tmantrap\tlauncher\tfarting\tlonghorn\tmimetic\tidiosyncratic\tbarbarous\thistory\tmallard\tcalendar\tantipodal\treplacement\tleader\tkeyword\thumming\trunabout\tswag\tthousandth\tdownplay\tambiguity\tperch\toverpowering\tmethod\tpropolis\tphilippines\ttransporter\tanil\tsuperstar\tprotect\tlinkup\tintersex\tbutter\tchronicle\tflea\ttoast\tbaghdad\tslant\tworshipful\tgoal\tsadness\tdividing\twisdom\tproblem\tlongan\tchronicler\tfibroma\taltarpiece\trecipe\tbird\tcomforted\thudson\tgripping\tveracity\tsnooker\tasperger\thorsebox\tweek\tmap\tcruiser\tappall\tlust\tfood\tkickoff\tmelting\tinvention\thousebreaker\tdeclamatory\tfeeder\tairfoil\tmasthead\tunhealthiness\tmastiff\talarming\tstogie\thummer\tcontemporary\tchew\tfamily\tsmoke\tjoshua\troots\tsimultaneous\tseaboard\tsuperinfection\tantler\tdaisy\tguestworker\tsplattering\tTesting 68/200\n",
            "baseball\ta sport played in the usa where you have to hit a ball with a bat\n",
            "\n",
            "sport\tmissus\tmilestone\tflea\tcontemporary\thorsebox\tgiraffe\tqueensland\tcity\tstagecoach\tbaseball\tintersex\tsplattering\trecipe\ttemporal\tmimetic\ttody\taunt\tclawhammer\tmoved\tt\tfaceted\tbus\tlose\tattacks\tlunch\tmessage\tmutual\tairfoil\tsmut\tskittle\tstubble\tclime\tstrangulation\tlinearly\tpostdate\ttransporter\tfreestone\tlongitude\tdog\tmethod\tinternet\techolalia\taccelerating\tshowstopper\tseminole\tsuperinfection\tstepping\tmouth\tfamily\tresort\tswallowtail\tchapter\tpincushion\tflathead\tcancer\tpipes\trode\tprotist\tknife\tcoyly\tmoni\tmantrap\tcopywriter\tdeathblow\ttakeaway\tender\telephant\tclown\tmonopoly\tpapa\ttrilobite\tdownplay\tlonghorn\tbenne\tremittal\tsmoke\treadied\tjjigae\tfeeder\tillegal\topera\thudson\tkindergarten\tlawman\tmansard\tcomplacency\tdaisy\tbobsleigh\tTesting 69/200\n",
            "sing\tto produce a tune or music with your voice\n",
            "\n",
            "limbed\tbask\tdrinkable\tjason\tafford\tinflation\tkalua\tliterature\tilk\tsectioned\tsimultaneous\tpaper\tdysuria\tdevastation\tcheap\tear\topera\tclandestine\tgrass\tseem\trisible\trattled\tfoot\tlongan\tmethod\thistory\tleader\tstagey\telongate\tsalem\tstereotype\tconcreted\tbloated\tknowledge\tphilippines\tsmoke\trudimentary\taqueous\trecommend\trooms\troots\timmigrate\tdeltoid\taliment\tvaledictory\trightful\tbird\tmonochromatic\tstemless\tmonotony\tgovernment\tvarnish\tknife\tunaccented\tlolol\tanal\tfacts\tcontemporary\tmining\tfishing\tchurch\tunderstandably\tdisjoint\tprints\terector\takan\tspeaker\tfaunal\tstroke\tthousandth\tsound\tchronicle\tpolitics\teyesight\tleggy\tbaths\tensure\tperpetuation\tt\toutset\tpiously\tmarsala\tmimetic\texhausting\tlimb\taviator\tender\thydrophobia\tsystem\tTesting 70/200\n",
            "safer\tmore safe than something else\n",
            "\n",
            "t\tlingua\twheel\tfella\tdisc\tclime\tsympathy\tstroke\tflight\tsmoke\treading\tbutter\tattacks\tknowledge\tsplattering\tleader\tinterred\ttargeting\tdance\tlust\tcrowing\tperistyle\tunlock\tchronicle\tregret\taimless\teffect\tretroactively\tlackluster\tjoshua\taviator\tgleam\tmap\tbegin\taflame\toffering\thackneyed\texpedite\tplayer\tpygmy\tsafer\tillusion\taqueous\ttelephone\tbegetting\tmentioning\tblueprint\tscreen\tshelve\theadache\tunderstandably\tcalendar\tsport\tconcreted\tgrass\tgoo\tsward\tdesk\tlolol\trainmaking\ttracks\tfun\tfowl\thorseshoes\tblimp\tsuperinfection\tdurn\tjobless\tunited\tnauseated\tcomplain\trescript\ttearfully\tsavoring\treflection\trepel\theist\taccelerating\tremain\tsilver\tchauffeur\tparadoxically\tcircles\tdetainee\tseltzer\tbask\texisting\tdiscourage\tmonet\tTesting 71/200\n",
            "improve\tto make something better\n",
            "\n",
            "smoke\tgrouped\tthousandth\tleggy\tloft\tj\tmouth\tplayer\tendurance\tpopulace\thudson\tice\temancipate\tcontemporary\taqueous\tperish\taby\tsympathy\tuh\tbaths\tkalua\tstereotype\terector\tpoke\tbst\tbullying\tlongshore\tarrester\tpliancy\tfinback\tthai\tgonzo\tprints\tgrass\tchurch\tjobless\tshrubland\tmap\texhausting\tdevastation\tlolol\tprod\tpostulant\tensure\telucidate\tschizoid\tgovernment\tconfuse\tcoloring\tarmy\tchocolate\tacquiring\tpuking\tillusion\texplore\tspy\tgolf\tgreen\tnewman\tshrewdness\tdomesticate\tperceive\tcommencement\tdemeaning\tlabradoodle\tdemean\tredo\talfresco\treload\tinfinitesimal\tstrep\tstoner\trecycle\tspiking\tlevy\troots\tkinescope\tmimetic\tphilippines\tvarnish\tseltzer\tdeboned\thopeful\timprove\tobjector\tmallard\tacademicism\txxx\tcamera\tTesting 72/200\n",
            "protect\tto take care of something and make sure that it is kept away from danger\n",
            "\n",
            "golf\tsuperstar\ttody\tpaper\tchapter\tfauna\trattled\tmethod\tlloyd\tplankton\tevaporate\tcaretaker\troller\tknife\tvestry\tstepping\tprotect\tconcreted\tworm\tchronicle\tlick\tsectioned\tscalpel\tbaghdad\tkickoff\tperch\thomework\thear\taltarpiece\tbb\tsequel\tbead\tprepare\tsmoke\texist\tdance\tpoke\tstar\tmarriage\tsupply\tafford\tlose\tremain\tairfoil\tsharing\tlake\tpiperine\tbus\ttermagant\tstovepipe\toffice\tfamily\timprove\tpander\tmonocyte\tsport\tchurch\tcontain\tattacks\tsnooker\tbring\tclawhammer\thangover\tilk\tjjigae\tbars\texplain\tkindergarten\tvasoactive\tstagecoach\thitchhiking\tbulleted\tgrow\taquamarine\tdaisy\tprevent\tstereotype\tisomerase\tperceive\tconsolatory\tnailing\tsolve\tsill\tmoni\tmorris\tpuking\tregret\tbegetting\treduce\tTesting 73/200\n",
            "receive\twhen somebody gives something to you and afterwards you have it\n",
            "\n",
            "prevent\tax\tgoverness\tcommunicate\tweek\tknowledge\telephant\tilk\trehabilitate\tbird\tprotect\timmigrate\tpassbook\tlose\tshrewdness\treceive\tt\tdakota\tconcreted\torientated\trestricting\tcheese\toropharynx\tender\tbaths\ttaste\tfishing\takon\tlick\tgreedy\tpaper\tsinglet\tinfinitesimal\tfood\tshearwater\tinternet\thorizontal\tstrep\tfeeder\tcalendar\tmelting\tbars\tattending\tear\tplayer\tchew\tbring\topera\tleavened\tfrankincense\tacoustics\tsound\tmarriage\tchurch\tsind\texhausting\tattacks\tpatient\tbell\trightful\tranting\tcontinue\tkalua\tmessage\taliment\ttruly\tseedbed\tinfallibility\tkindergarten\tuser\tswimming\terector\tpolitics\tbegin\tlust\trace\twashed\tprovided\tresorption\tfur\tkinescope\tbullying\tshelve\tstealthy\twrite\tswag\tcrematory\tflea\tfollow\tTesting 74/200\n",
            "explore\tto look around a new place going to all of the different parts so that you know it better\n",
            "\n",
            "protect\tinvest\tlibrary\tbulleted\tgreen\tpander\tpolitics\tloach\tbars\ttoast\tcaretaker\timprove\tattractor\taltarpiece\tbiotite\trace\thear\tbus\tvestry\tnewman\tcalendar\tmaintain\troller\tisland\tanchovy\tconcreted\tbullying\tmanaging\tmastiff\tmouth\tfirearm\tlose\tfood\tlick\tsheet\tpoke\tdog\texplain\trequire\tsurgery\tillusion\tchronicle\toffice\tsolve\twrite\ttracks\tbring\tfollow\tsnooker\tchurch\tbegetting\tilk\tmarriage\tfamily\tbell\tmethod\trattled\tgripping\tblanket\tcircles\trealize\tpiperine\tscreen\tfibroid\tmallard\tafford\tfur\tliterature\tachieve\tsilver\tweek\treload\tbend\tknife\tdefoliated\tclandestine\tlugnut\tgrep\tpincushion\tfight\tdepend\tlongan\tlayer\tplankton\tallow\teast\thudson\tgolf\timpact\tTesting 75/200\n",
            "ensure\tto make it certain that a particular event will happen\n",
            "\n",
            "malware\tmosquitofish\tconsolatory\tdenaturant\tinterrupt\tcamera\tscuba\thear\taudience\tmarriage\tanimal\tsprouting\tenglish\taltarpiece\tfamily\tmap\ttoast\treading\thydrophobia\tlactone\tbring\tvideo\tdefoliated\tanticlimax\tendurance\thudson\ttakeaway\tfirearm\them\tdog\tfauna\tsnooker\ticebreaking\taccelerating\tcaretaker\tensure\tdemeaning\tlose\tlloyd\tay\tteachable\tblimp\tsob\tilk\tlackluster\ttrilobite\ttruly\ttody\tseem\tjjigae\tgolf\tnegotiation\tknife\tspoofed\tmimetic\tlaugh\tmacdonald\tdiscourage\titu\tgrass\tacoustics\ttheta\tsympathy\tcultivate\tgeneralized\tgreen\tdepository\tcalendar\tranting\tfurred\tremodeling\tpurifying\tlumbago\thiker\tt\texplain\tdemean\thorizontal\tnational\tpresident\tsociety\tawning\tdisc\tmortgage\tbars\tnailing\tfollow\tprepare\tsalem\tTesting 76/200\n",
            "smoke\tthe substance that emerges from a fire when wood is burned\n",
            "\n",
            "melting\tzoology\tgrow\tabalone\tsubtlety\tsinglet\tantler\tsquealing\tclown\tperish\tparabolic\tdiscover\takon\tpostoperative\tpurifying\tinterventionist\tgregarious\tcontain\tcrematory\tangiography\tsojourn\tremittal\trudimentary\tupgrade\trace\tcouched\tsalary\twhelk\tswag\thermeneutic\tbaths\tpigweed\tsmoke\tay\tax\tstubbled\tbulleted\tfashioning\tsari\tcaretaker\tantipodal\teyesight\tdisposed\tfortnightly\tdefoliated\tshrewdness\trehabilitate\tability\thackneyed\tflathead\tpiperine\tslant\tperspicacity\tsolidarity\ttoast\tbird\ttoppings\tsnowplow\tanchovy\tshearwater\tconjunctive\thudson\tfollow\tpatient\tclothing\tflippant\tlose\tlloyd\thear\ttechnology\tbaghdad\treferent\tgeostrategic\tsnooker\tsadness\tstickleback\tcalendar\tlev\thopeful\tobjectivity\timmigrate\tmud\tweek\tprevent\tplankton\tuntreated\tlonghorn\tamenities\tpaleta\tTesting 77/200\n",
            "daisy\ta flower with small white petals and a fuzzy yellow centre\n",
            "\n",
            "translator\tpapa\tbaghdad\tbenne\tgreedy\tgeneralized\tdurn\treb\tclime\tcomforted\thudson\tfun\tjjigae\tanil\tdomestication\tchapter\twood\tmoved\tattacks\tasean\thumming\tsuperstar\tmimetic\tbutter\tdaisy\tskateboarder\tmalware\tkalua\tspiking\tconcreted\tthoroughgoing\tcruiser\ttoast\tstovepipe\tanchovy\tlauncher\tlloyd\tserotonin\tdiscreditable\tnewman\tworm\tsnooker\tthrush\tdisc\tcowpox\tbird\tgregarious\tbullying\tdemodulator\tniggle\tfurred\tanimation\taltarpiece\tbluster\tqueensland\tsnotty\tflatly\tvideo\ttruly\tstealthy\troller\tinoculation\thopeful\tchocolate\tbonemeal\taimless\timpedimenta\tjuggle\tillegal\tdrinkable\tspecies\ttargeting\tweek\tbars\tmatthew\tcelibate\tthymol\tvom\tromance\tbst\treload\tillustrator\timpact\tteachable\tremittal\tbrawny\tcache\tswag\tunited\tTesting 78/200\n",
            "castle\ta large building made of stones that is easy for an army to defend\n",
            "\n",
            "bead\tstovepipe\tfight\tredo\tprotect\tstepping\tacademicism\tpaper\tcaller\tsavoring\tdemean\tvestry\tpetrol\tbulleted\troller\tdemeaning\tphencyclidine\tfashioning\tphimosis\ttoast\tprefer\tspread\tsolidified\tmethod\tsilver\thomework\tknife\tfeeder\tplankton\tmalware\tmindscape\tdiscover\tconjunctive\tprepare\thitchhiking\tceiling\treading\tspringhouse\tliquify\tcrock\tsnowplow\tducks\trattled\tcelibate\tsheet\tcontinue\tmallard\toffice\tsurgery\tprevent\tay\tchoose\tilk\tcheese\tsharing\tsemantic\tpizza\tenslave\tability\troots\tcaretaker\tbilious\taltarpiece\tslant\tseminole\treflection\tmelting\tflathead\tobjectivity\tdurn\tbenne\tstar\timprove\tlayer\tdelectable\texisting\tremittal\tkickoff\tchurch\tdeltoid\texchangeable\tindecency\tpatency\tmonocyte\tdeliverable\tbrazier\tpander\tmoni\tsubcutaneous\tTesting 79/200\n",
            "road\ta track or route for cars and other motor vehicles\n",
            "\n",
            "moved\tcartier\tpresage\tplayer\trainmaking\tuser\tretrogressive\tqueensland\tclime\tfun\terector\treb\tluddite\tum\tchapter\tmutual\tflighty\tbbl\tpride\tkalua\trudimentary\tposeur\tbreakwater\thomework\tcancer\textraterritoriality\tfree\tsuspected\tdakota\tpapa\tillegal\tanimation\troad\tchickenshit\tkisser\tinfallibility\tfey\tmantrap\tcockeyed\temergent\tphilippines\tbonemeal\that\taspirate\tbooby\tjjigae\tgyroscope\talfresco\tbaghdad\tprotist\tcoconspirator\tpatient\tbarring\tcraps\tmimetic\treload\tdisjoined\tvom\tfoot\tasean\tbrazier\tstagecoach\tpizza\tpackaged\tdomestication\tbrawny\tremittal\tmonopoly\ttranslator\tpursuer\tnews\tinfinitesimal\tbounded\tdeltoid\texisting\tfaceted\tranking\troots\tvideo\tderisory\tbird\tchemosynthesis\triver\tchagrin\tstoner\tbilious\tethylene\tpigweed\tinquisitorial\tTesting 80/200\n",
            "love\ta strong emotional feeling of physical or mental attraction towards somebody\n",
            "\n",
            "expansionary\tqueensland\tfaunal\tstomach\tlick\treload\tbaghdad\timpoverish\tpresently\tgreedy\tbleak\tmarsala\tseminole\trudimentary\tdrinkable\tpestilent\tlackluster\tfurred\tclandestine\tlascivious\tinfinitesimal\tsinglet\tinquisitorial\takon\tvaried\tsalem\tbrawny\tweek\tdene\tantipodal\tcaretaker\tclime\thousebound\talarming\tantler\tshifty\tseltzer\tdisposed\tstealthy\tthoroughgoing\tcounterintuitive\tvideo\ttechnology\tastride\ttraineeship\tgau\tphilippines\tliterature\tmap\tendorphin\trace\tcontemptuous\tidiosyncratic\tmimetic\tmud\thyperspace\tsympathy\tprohibitory\texcess\tjuice\tillegal\thorizontal\tdog\tcheese\tbenne\tgregarious\tnature\tfur\tmouth\tbird\tgeneralized\tunited\tbring\tcity\tviscera\tphysiologic\tdiscreditable\tfruit\trehabilitate\trooms\tdomestication\tfollow\tswimming\tstrep\tsnooker\tswag\tamenities\tprints\tsqueamish\tTesting 81/200\n",
            "family\ta group of people like a mother father and children who are all related\n",
            "\n",
            "paleta\tdemented\texcess\tlick\tliterature\tmouth\tmundane\tlederhosen\tlose\tgregarious\tphilippines\tsprouting\tsociety\teffect\tmonotony\tfashioning\tthoroughgoing\tfollow\tcaller\tbarring\tethic\tfurred\tsadness\texplain\tknife\tsilver\tsympathy\tgolf\treading\tfibroid\tsolidarity\trace\tendurance\tornithopod\tmastiff\thumming\tmilitarize\tillusion\tamenities\tswag\tbring\tbus\tsqueaking\tblimp\tvideo\tlevy\tantler\tchurch\tcontemptuous\tpursuer\tarbovirus\tdog\tilk\tkindergarten\tfamily\tflea\tgraben\tpaper\tbreakwater\tbaghdad\tnature\treload\tpinpoint\tshifty\tice\tidiosyncratic\tcartier\tmap\tastride\thorizontal\tisland\tjjigae\tlove\tmeat\tlactone\tmud\talarming\tfood\tvee\tlaryngitis\tlonghorn\ttechnicality\tkibitz\tunderage\tdivinity\tremain\tmanaging\tperspicacity\ttaste\tTesting 82/200\n",
            "supply\tto regularly provide people or an organization with things\n",
            "\n",
            "island\tambiguity\tkickoff\tfacts\tmonotony\tmethod\tthoroughgoing\tinflation\tmimetic\tfound\tbullying\tprints\tunrestricted\tspotter\tidyllic\twood\tsequel\ttruly\tpestilent\tbonemeal\tsectioned\twashed\tlust\tknife\tilk\titu\tstrawberry\tgrass\tbb\tdevastation\tveracity\tleader\tthousandth\tkalua\tincremental\thydrophobia\tcheap\tdry\tnirvana\tmud\tgreen\tdakota\taqueous\tsharing\tice\tqueensland\tcontemporary\troller\tender\teyesight\tpatient\tfamily\thudson\tpaper\tlloyd\tclandestine\troots\tnickelodeon\tinsufferable\tcaretaker\treadied\tsojourn\tnewman\tuh\tgonzo\tdog\terector\tacademicism\tlongitude\tmentioning\tshrewdness\tpapa\toligarchy\tsalt\tbauble\tprovided\tsound\tscreen\tpostulant\tgripping\tlayer\tbst\tsmoke\tchronicle\tstereotype\tillusion\texisting\toffice\tablation\tTesting 83/200\n",
            "straw\ta thin tube that you can use to drink a drink through\n",
            "\n",
            "glyceryl\tfollow\taliment\tsnow\tlonghorn\tsharing\twine\trequire\tunlawful\tnuptials\tlevy\tknife\tgregarious\thumming\tpanoply\trecommend\tvioloncello\tfrantic\twrite\tcommerce\thorizontal\tsequel\tice\tspeak\tprints\tarmy\tstomach\tsandstorm\ttelephone\teec\ttaste\tgreedy\tilk\trace\tstealthy\tsari\tlust\tt\tantislavery\tcavy\thair\tremodeling\tswimming\taudience\tspeaker\thydrophobia\tdivide\tgrow\tablation\tfarting\timmigrate\texplain\tknowledge\tthoroughgoing\tenergize\tmouth\tspindly\tfood\tgambrel\ttruly\tcultivate\tlick\tdemean\treadied\tstrep\taccelerating\tdemeaning\tay\tgeneralized\tpestilent\tbring\tleavened\tdrinkable\tmouse\tballoons\toccidental\tphilippines\tforget\tcache\tbluster\treading\tfruit\therbarium\tflea\tfirearm\trely\tincubate\toutstay\tglass\tTesting 84/200\n",
            "confuse\tto make something hard to understand or to make it hard for someone to understand something\n",
            "\n",
            "moved\tice\tpostdate\twood\thorizontal\tattacks\thangover\tautism\tworm\taccelerating\ttope\tbluster\tmimetic\tlactone\tspeak\teast\ttheta\tgrass\them\tcircles\tpaper\tglass\tilk\tcity\ttranslator\tillusion\tfeeder\tkindergarten\tpanoply\tthanks\taunt\tenglish\tcontemporary\tbrazier\tchoose\trode\tmenu\tdog\tperforator\tcaretaker\timprove\tcosmologist\tscaleless\ttakeaway\tfur\tmap\ttaste\tboyfriend\tsympathy\tseaboard\tfurred\tjjigae\tsociety\tsilver\tknife\tredo\tevaporate\texplore\thydrophobia\tsupply\tbasketball\tdurn\tetching\tmasticate\tclime\tpipes\taltarpiece\tdrinkable\tsavoring\tfight\tlotus\tdisestablishment\trile\tbring\tmortgage\tambiguity\tbus\tfun\tobjector\tleader\thitchhiking\tgiraffe\tsilverside\tpostulant\tlick\tender\tbars\thorseshoes\tlust\tTesting 85/200\n",
            "news\trecent information about the world often distributed via the media\n",
            "\n",
            "thoroughgoing\ttheta\tclothing\tjjigae\tknife\tmimetic\tmediaeval\tseminole\tbaghdad\tjoshua\tbooby\taunt\tpatient\tsharing\ttea\thudson\tcourtliness\trattled\tneuropathy\troadrunner\textraterritoriality\tax\tdakota\tsalami\tchapter\tdownplay\tpeshmerga\twing\tnirvana\torientalist\taltarpiece\tgiraffe\tangiography\tkalua\tillegal\tmarriage\ttoast\tbonemeal\tstrawberry\tmatthew\tgrass\treb\tdurn\tilk\tmarsala\tslideshow\tclandestine\tfun\tcatherine\tisomerase\tslant\therpes\tcatastrophe\tinternet\tweek\tdysphasia\tchronicle\tmonocyte\tsalt\tnews\tpapa\tfreestone\tcontemporary\tbulleted\tspurge\timmigrate\tprotist\tvom\tloach\tchemosynthesis\tanil\teyespot\tremittal\tsojourn\taspirate\tbarring\tcosine\tlaryngitis\tbullying\tlongitude\tnewman\tblimp\tluddite\tfibroid\ttracks\topera\tart\troots\telephant\tTesting 86/200\n",
            "message\ta small amount of information passed between two people\n",
            "\n",
            "prevent\tvarnish\tremember\tflea\tcheese\tice\tdakota\tdescribe\tshearwater\tleader\tgrass\trattled\tcowled\tqueensland\tshifty\tknowledge\tbb\tbloated\taliment\tdoubling\tsharing\trudimentary\tsheet\tspecial\tmessage\tbarge\tducks\tdisjoint\tchemosynthesis\teast\tshrewdness\twood\tsport\tmosquitofish\tclandestine\tpromotion\thudson\tuser\tunfashionably\tinfinitesimal\tpolitics\tsimultaneous\tblather\tnoninstitutionalized\trecklessly\thomework\tperestroika\tkickoff\tbst\tkalua\theadache\torientated\tchildhood\tmap\tbegin\tflathead\tmortice\tgreedy\tstepping\ttenancy\tobjectivity\tphilippines\tmatthew\tbitters\tfoot\thorizontal\tunrestricted\tchagrin\tpresident\twashed\texhausting\tspeaker\taqueous\tindivisible\tfingerpointing\tanal\ttea\tcockeyed\tbars\tceiling\taccelerating\tbonemeal\tsea\tunmeasurable\tmediaeval\tagouti\tenglish\trace\troadrunner\tTesting 87/200\n",
            "speak\tto form words with your mouth so that you can communicate with other people\n",
            "\n",
            "church\telephant\toropharynx\tallow\tfauna\tmessage\tecliptic\trealize\tsympathy\thomework\tlose\tgreedy\tcheckered\tcommunicate\tambiguity\tfeeder\tblanket\tnegotiation\tilk\tdomestication\ttaste\tvideo\tachieve\tawning\trushes\textraterritoriality\tprotect\tafford\tfood\tillusion\tthanks\tideas\tspeak\tsharing\tconfuse\tseem\tpreventive\tinflated\tlake\tchoose\tresort\tlove\tbring\tstagecoach\treaction\ttrifle\tmastiff\tkindergarten\trudimentary\tremember\troadrunner\tclown\tsind\tglass\tpolluted\tthwarting\tfruit\tfashioning\tcrock\tcontinue\tdeltoid\tworm\temergent\tlysis\tfun\tprobable\tmonopoly\tremain\tangelic\tsectioned\tdysuria\tlick\tantislavery\ttody\tconcreted\tknife\tvenereal\tdonut\tupgrade\tkibitz\tpoke\tlevy\ttemporal\tdog\tdescribe\tanil\tsill\tsupply\tinterrupt\tTesting 88/200\n",
            "rely\twhen you regularly use something or somebody to do something and you would not be able to do it otherwise\n",
            "\n",
            "baghdad\tflea\tax\tweek\tvideo\tfrankincense\tosteoporosis\tfeudalism\tcastle\tshowstopper\tdownplay\temergent\tgreedy\tspirochete\tlonghorn\tisland\tstagecoach\tcommunism\tconvenor\tbird\tmouth\tlake\twashed\tsidecar\ttundra\tdesk\tcalendar\tcavy\tfibreboard\taltarpiece\tpolitics\tgoal\tfirearm\tstumping\tcheesecake\troller\tspeaker\tgenocide\theadache\tgeneralized\ttea\timmigrate\tt\tprotist\tunderscore\tsheet\tfun\tagouti\tsalem\tpatent\tjjigae\tlayer\tgripping\tmonotony\tinfinitesimal\tthousandth\tbutter\tclandestine\tfibroid\tfruit\tcancer\trequisition\tillegal\tchew\tmimetic\tdrinkable\tgregarious\tchronicle\tmasturbation\ttrilobite\tflippant\tdog\tfeeder\tmarsala\tphilippines\tbleak\tangiography\tilk\tinternet\tpaper\tshearwater\tfamily\tkalua\tshocked\tthoroughgoing\tsinglet\ttoast\tslant\tpestilent\tTesting 89/200\n",
            "prepare\tto get yourself or something or someone else ready to do something\n",
            "\n",
            "banking\treliving\tsmoothed\taqueous\tsoup\tdiscourage\tclandestine\tsectioned\tleader\thangover\treadied\tshocked\tcapsizing\tbluster\tattacks\tmatthew\tchocolate\tmentioning\tcircles\tdisc\tsilver\tsalem\tconcreted\tsympathy\terector\texisting\tprepare\ttope\tscreen\taimless\tstar\tperish\tlolol\ttargeting\tlake\tbb\tschizoid\thorizontal\tdance\tconsolatory\toccur\tsea\tcontroller\tclime\tsequel\tchronicle\tleavened\toveremphasise\twood\topportunity\treload\tfive\tmouse\tworm\tsmoke\tmonographic\ttruly\tpsychology\tender\tlloyd\tunited\texotoxin\timprove\twashed\tsuperstar\tpuking\tbask\tdaisy\tdistractedly\tbring\tpelota\tglass\tpanic\twheel\tstepping\tpaper\tliquidity\tgleam\tsnow\tknowledge\tlove\tsurcharged\toropharynx\taltarpiece\tgreedy\tdeboned\tfun\tstroke\tmessage\tTesting 90/200\n",
            "army\ta group of men who fight together in the name of a country\n",
            "\n",
            "exchangeable\therpes\tfrontmost\tteachable\tlaryngitis\tbird\tbarbarous\tcommunism\tsmoothed\tseminole\tliterature\tbioelectricity\thudson\tgenocide\tbenne\tstealthy\takon\tdiscordant\tcheese\tfruit\tbeech\tflathead\tillegal\tswag\tstarfish\tbleak\ttuberculous\tarmy\tplimsoll\tdisposed\tspeaker\tstumping\tlederhosen\ttrilobite\thydrophobia\ttoast\tcoyly\tjuggle\tcowpox\tsmutty\tgoo\tpresident\tslant\tsparse\tdrinkable\tshearwater\tpolluted\tdomestication\tgeneralized\tstubbled\tmesenteric\tmanaging\teyesight\tprovided\tinsufferable\tunfeeling\tdemeaning\tbst\tpresently\tchew\troller\tax\teyeglasses\tstickleback\tfictive\taudience\tfinger\tmatthew\ttrichromatic\tdemented\tswallowtail\trooms\tpigweed\tleader\tsurgery\troadrunner\tmediaeval\tundependable\tbrawny\trode\tdiscourage\tincubate\tdodgy\tpardoned\twing\tegomania\trectus\thair\tapprehend\tTesting 91/200\n",
            "fight\ta physical confrontation where people try to hurt each other\n",
            "\n",
            "generalized\thitchhiking\tillegal\tprogramming\tilk\tvideo\tinfinitesimal\tisland\tuser\tphilippines\tmilitarize\treadied\tclapper\tbluster\tperish\taccelerating\tbutter\tthumbed\tmundane\toveremphasise\tthoroughgoing\treload\tfollow\tnewman\tbullying\tremain\tclandestine\toffice\trace\tsociety\tt\tlackluster\tgregarious\tmethod\taltarpiece\thumming\tcamera\tsari\texpressible\tvioloncello\tmoved\twashed\tcheese\tgreen\tbonemeal\tdefoliated\tinterrupt\tcaretaker\tsympathy\texpansionary\thopeful\tmap\tbegin\tsilver\tnegotiation\tsolve\tchurch\tbiotite\tfibroid\tknife\tsea\tknowledge\tlick\tbulleted\tlloyd\tresort\tsnooker\tstrawberry\tprod\trigid\tdeboned\tgreedy\tcontemptuous\tfur\tpaper\tmalware\tantipodal\tbelvedere\tbus\tcheckered\thorizontal\tfauna\ttruly\tpapa\tjjigae\trattled\tamaranth\tscuba\tbaghdad\tTesting 92/200\n",
            "camera\ta machine for taking photographs\n",
            "\n",
            "brawny\tideational\tunreliability\tkisser\tgowned\tcopywriter\tgrass\tplayer\tcancer\timpact\tmutual\tpumice\tdog\tthrombolytic\twimbledon\tsympathy\tanal\tlumbago\tuptempo\tnitrobenzene\tstraw\tsalt\tuser\tdevelopment\twashed\tgrifter\tcontemporary\ttickle\tcamera\tswimming\tmasturbation\thotness\tbarmaid\tbarring\tlouvre\tdrinkable\tberried\tmimetic\tswindler\tanglicised\tspeller\thumming\tsalem\tlotus\tcraps\tambulatory\tenglish\tparliamentarian\tcity\tmantrap\tbehavior\tpygmy\tluddite\tlauncher\tsump\tflatly\talfresco\tapothecary\tsport\tpunter\tprotist\tice\tfitfully\tmusic\toverlapping\tflea\tfun\tarcadian\tcowherd\teros\tnational\tmeat\tmormons\tpresently\tfey\thorizontal\trainmaking\tinositol\tzoology\tosteoblast\tcharisma\tpresident\tchagrin\tleavened\tflight\tqueensland\tpizza\tbrahminical\tsurcharged\tTesting 93/200\n",
            "music\tnoise that is tuneful and people listen to for pleasure\n",
            "\n",
            "speaker\thopeful\tscottish\tmouth\tflight\tstealthy\ticily\tthoroughgoing\tsprouting\taliment\treplacement\takon\tstomach\tanal\tswag\trooms\tshocked\tgreen\ttea\taby\tthoroughness\tbird\tcontemptuous\trecklessly\tlloyd\tmoved\tpacing\tsimultaneous\tsolidarity\tgovernment\tunderscore\treferent\tblather\tconfuse\tremain\tcockeyed\tjuice\treading\tspindly\tgregarious\tinfinitesimal\tstrep\tgeneralized\tkindergarten\tfurry\tdemeaning\tcheese\ttoast\texhausting\taudience\tswimming\thudson\tflatly\tensure\tay\ttoastmaster\tdodgy\tkalua\tscuba\tzoology\tmusic\ttruly\tlongan\tforget\trudimentary\tleavened\tdog\tteachable\tsnotty\tlopsidedly\timpotent\tbbl\tbioelectricity\tarmy\tshrewdness\tplayer\tnirvana\tbell\tphilippines\tice\tdakota\thorizontal\tdiscreditable\tflippant\tdrinkable\tmatthew\troad\tthumbed\tinfallibility\tTesting 94/200\n",
            "recommend\twhen you tell other people that something is very good and the right choice\n",
            "\n",
            "gripping\tremain\trushes\tsupply\tfurred\tgolf\tfur\tlust\tkindergarten\treplacement\tremodeling\tfeeder\triver\tlose\tender\tsociety\ttemporal\tambiguity\tamenities\thorizontal\tboyfriend\tredo\tupgrade\texchangeable\tunited\tthanks\ttugger\tmidsized\tlick\tenergize\tdiscourage\tinfinitesimal\trecipe\tinanimate\tallude\tcraps\tsqueaking\tclown\trationed\teffect\tensure\tgrunt\tcaretaker\treceive\tinfallibility\tlake\tinterrupt\tlevy\troad\tmap\tproblem\tslant\tmundane\tendocannabinoid\tlongshore\ttaste\tuh\thear\tworm\tdog\tveracity\tshrillness\tsolidarity\taqueous\tmoved\treading\tsavoring\tcircles\toutset\tice\tpaper\tawning\tbelting\tconfuse\tfoot\tanil\tswag\taudience\tsympathy\tbauble\thistory\tperish\tfood\ttwofer\tclandestine\tfurry\tbird\tshelve\tcommiserate\tTesting 95/200\n",
            "headache\ta feeling of pain in the head or brain\n",
            "\n",
            "sport\thangover\theadache\taviator\tender\tachieve\taimless\tclime\tsupply\tbluster\tattacks\tgleam\tstepping\ttope\tmentioning\tsharing\tmessage\tthanks\textrude\tvaledictory\tstagecoach\tnorma\twood\toutset\tinfantilism\tdivide\texcess\tpostdate\trecommend\tneedlessly\tmap\tconcreted\tevaporate\tdivertissement\tlawman\tdance\tpanoply\tkindergarten\ttakeaway\ttea\troots\tpaper\tpatent\tshelve\tbegin\teros\tstomach\tidentify\tswag\tfaceted\tfoot\tenergize\trecklessly\tqueensland\tcalendar\torchard\tstroke\tlysis\tflight\tpipes\treadied\tmilitarize\tmoved\tfingerpointing\tknowledge\thereditarily\tlick\taunt\tinternet\ttelephone\tscreen\tcontinue\thomosexualism\tshocked\tpapa\trenominate\tgoal\taltarpiece\tplatoon\techolalia\treckoner\tleapfrog\trudimentary\tclimate\tdescribe\tperch\texternally\tstainer\tsequel\tTesting 96/200\n",
            "ceiling\tthe top often flat surface of a room\n",
            "\n",
            "rabble\tbegin\tdisc\tclothing\tbus\tmatthew\tsawhorse\tnirvana\tairs\trace\tgrass\tmacdonald\tdaisy\tcoreopsis\tbend\teyesight\tformaldehyde\tsnakelike\tchurch\tangiography\tpurchase\tcheap\tenglish\tsmutty\tshepard\tice\tcheese\tdesk\trationed\tanil\tdeboned\tjason\tceiling\tblimp\thydrophobia\tsympathy\tclandestine\thudson\toffice\tobtain\tpaper\tlloyd\tabdication\taboveboard\thorizontal\tsilver\tpaleta\tcourtliness\tdebugging\thackneyed\tducks\tbioelectricity\taudience\tthoroughgoing\tserotonin\tbaths\tseriocomic\tstairs\tflatly\txxx\tpander\tgeneralized\tvideo\tbulleted\tnegotiation\tincremental\ttruly\tstrawberry\tbelvedere\tbead\tmosquitofish\tcamera\tkeyword\tspiking\tbonemeal\thitchhiking\tpiously\tj\tdefoliated\tlackluster\tsprouting\tprevent\tdurn\tpetrography\tperish\tmoa\tcache\tsnotty\tsea\tTesting 97/200\n",
            "flight\ta journey in an aeroplane or the act of travelling in the air\n",
            "\n",
            "calendar\tfarting\tlauncher\thousebreaker\terector\tdeathblow\tcomforted\tcamera\tgrass\tstraw\tflight\tsulking\tattacks\ttransporter\ttaste\tcheap\tmorgen\tscottish\ttranslator\tbetty\taccelerating\tlactone\tdrinkable\ttakeaway\tpanoply\tsupply\ttargeting\tgrow\tlinearly\tspeaker\ttickle\tmantrap\tdevelopment\tmediaeval\tcontain\tshowstopper\tfrontispiece\tspangled\tflathead\tpunter\tremember\tsummertime\tsicken\tvee\tcaller\tsea\tpuncturing\treplacement\taudience\tcastle\texpect\tperceive\tblue\tleader\tsing\tflatly\tarmy\tmycologist\ttoast\tgovernment\tbird\trecklessly\tplayer\tscreen\tpride\tlake\tattuned\tuptempo\tbaseball\tdepend\tsurcharged\tinvention\tprevent\talfresco\tunaccented\tallude\tstickiness\tsprouting\tsnowplow\tcancer\tmenu\tdebugging\tstrawberry\tstumping\tmasculinity\treferent\tslab\tbeech\tthrombolytic\tTesting 98/200\n",
            "afford\twhen you have enough money or time that you can do or buy something that you want\n",
            "\n",
            "panic\tsnickers\tdemeaning\tsurcharged\tpurifying\tdiscourage\tanchovy\trowboat\tspread\tallude\tlust\tsward\tremodeling\tcarburetor\tkeyword\tairfoil\thear\tsolidarity\tredo\tplankton\tsupply\tpander\tcontain\tfun\tproblem\trationed\toffice\tstovepipe\tinterrupt\tdeathblow\tbursting\tworshipful\tremain\tjjigae\trattled\tthanks\tmanaging\tinositol\tlibrary\tcheap\tpaper\thistory\taltarpiece\tevaluate\tinfinitesimal\tnailing\tsilver\tsplattering\thitchhiking\tidentify\tunprovable\tbaths\tknife\tregret\tsuperinfection\tdemean\tpostulant\tbend\tinvention\tfurred\tteachable\tmastiff\tfeeder\tunrestricted\tapplier\tsalary\toverpowering\tgents\tsprouting\tcircles\tpropolis\tsavoring\tgrass\tcomforted\tsport\tforget\tfrontispiece\tveracity\treduce\tlonghorn\tfight\ttopically\tsympathy\tcomplain\tcalendar\tlove\thydrophobia\tshrubland\tdormitory\tTesting 99/200\n",
            "chocolate\ta popular brown sweet made with milk and cocoa\n",
            "\n",
            "island\tarrester\taqueous\ttench\tsnooker\tsound\tinterred\tcommiserate\tgreedy\tregret\trattled\topera\tillusion\tcontemptuous\tmosquitofish\tantipodean\tkinescope\tperestroika\tpentoxifylline\tcommencement\tpresently\tjuice\tchocolate\tfacts\tflashiness\tbead\tbars\tunited\tillegal\tbarring\tstrawberry\tsynopsis\tknowledge\tprohibitory\tpaper\tballoons\tmarsala\tfarce\torientalist\trace\tnews\tgonzo\tbulleted\tsemantic\taliment\tgraben\tmethod\tlloyd\tchurch\tblanketing\tsilver\ttwofer\tsympathy\tthrush\tsea\tsmoke\troots\ttoast\tprovided\tinfinitesimal\troad\tcheap\tcaretaker\tidentify\tconformism\tanil\tglass\tambiguity\tprints\tbask\tdakota\texpedite\tlassitude\tcowpox\toverbridge\tshepard\tprotect\trevolt\trationed\tkeyword\toffering\tbutter\tfinger\treplacement\torientated\tformaldehyde\tlayer\tresort\tcoexist\t"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-29244be71679>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# print(predictions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mA_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA_10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA_100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mground_truth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy @ 1 = \"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy @ 10 = \"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'evaluate_test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcMz9urBQ6qT"
      },
      "source": [
        "import numpy as np\n",
        "def evaluate(ground_truth, prediction):\n",
        "    accu_1 = 0.\n",
        "    accu_10 = 0.\n",
        "    accu_100 = 0.\n",
        "    length = len(ground_truth)\n",
        "    for i in range(length):\n",
        "        if ground_truth[i] in prediction[i][:100]:\n",
        "            accu_100 += 1\n",
        "            if ground_truth[i] in prediction[i][:10]:\n",
        "                accu_10 += 1\n",
        "                if ground_truth[i] == prediction[i][0]:\n",
        "                    accu_1 += 1\n",
        "    return accu_1/length*100, accu_10/length*100, accu_100/length*100\n",
        "\n",
        "def evaluate_test(ground_truth, prediction):\n",
        "    # print(ground_truth)\n",
        "    # print(prediction)\n",
        "    accu_1 = 0.\n",
        "    accu_10 = 0.\n",
        "    accu_100 = 0.\n",
        "    length = len(ground_truth)\n",
        "    pred_rank = []\n",
        "    for i in range(length):\n",
        "        try:\n",
        "            # print(i)\n",
        "            # print(prediction[i].tolist().index(ground_truth[i]))\n",
        "            pred_rank.append(prediction[i].tolist().index(ground_truth[i]))\n",
        "        except:\n",
        "            pred_rank.append(1000)\n",
        "        if ground_truth[i] in prediction[i][:100]:\n",
        "            accu_100 += 1\n",
        "            if ground_truth[i] in prediction[i][:10]:\n",
        "                accu_10 += 1\n",
        "                if ground_truth[i] == prediction[i][0]:\n",
        "                    accu_1 += 1\n",
        "    print(pred_rank)\n",
        "    return accu_1/length*100, accu_10/length*100, accu_100/length*100, np.median(pred_rank), np.sqrt(np.var(pred_rank))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrPzyQq8TfQH"
      },
      "source": [
        "from keras.models import model_from_json\n",
        "json_file = open('modelPOS.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "modelPOS = model_from_json(loaded_model_json)\n",
        "\n",
        "definition = input().lower()\n",
        "#print(definition)\n",
        "words = definition.split(' ')\n",
        "idxs = []\n",
        "POS2idx = OrderedDict([('<start>', 0), ('<end>', 1), ('noun', 2), ('verb', 3), ('adp', 4), ('det', 5), ('conj', 6), ('adj', 7), ('adv', 8), ('prt', 9), ('pron', 10), ('num', 11), ('x', 12), ('ADV', 13), ('NOUN', 14), ('VERB', 15), ('ADJ', 16), ('ADP', 17), ('DET', 18), ('PRON', 19), ('NUM', 20), ('CONJ', 21), ('PRT', 22)])\n",
        "idx2POS = OrderedDict([(0,'<start>'), (1, '<end>'), (2, 'noun'), (3, 'verb'), (4, 'adp'), (5, 'det'), (6, 'conj'), (7, 'adj'), (8, 'adv'), (9, 'prt'), (10, 'pron'), (11, 'num'), (12,'x'), (13, 'ADV'), (14, 'NOUN'), (15, 'VERB'), (16, 'ADJ'), (17, 'ADP'), (18, 'DET'), (19, 'PRON'), (20, 'NUM'), (21, 'CONJ'), (22, 'PRT')])\n",
        "for word in words:\n",
        "    idxs.append(POS2idx[word])\n",
        "\n",
        "idxs = np.array([0] + idxs + [1]).reshape((1,len(idxs) + 2))\n",
        "\n",
        "POSprediction = modelPOS.predict(idxs, verbose=0)\n",
        "# index = np.argmax(prediction)\n",
        "ind=np.argpartition(POSprediction[0],-3)[-3:]\n",
        "for i in ind:\n",
        "  # meaning = idx2word[index]\n",
        "  tags = idx2POS[i]\n",
        "  print(tags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k38zMj5AB2kT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88fe2710-f165-4188-9a37-5ea484140fb6"
      },
      "source": [
        "!pip install flask-ngrok\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask, request, jsonify, render_template, logging \n",
        "import webbrowser "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flask-ngrok\n",
            "  Downloading https://files.pythonhosted.org/packages/af/6c/f54cb686ad1129e27d125d182f90f52b32f284e6c8df58c1bae54fa1adbc/flask_ngrok-0.0.25-py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (1.1.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.2)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=0.8->flask-ngrok) (1.1.1)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EP40SP1Acct",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0322be84-d07f-4ecd-ea13-98906f01cadc"
      },
      "source": [
        "def create_app():\n",
        "    app = Flask(__name__, template_folder='drive/My Drive/Colab Notebooks/templates', static_folder='drive/My Drive/Colab Notebooks/static')  \n",
        "    return app\n",
        "    \n",
        "app = create_app()\n",
        "\n",
        "#WEB-APP\n",
        "@app.route('/', methods=['GET', 'POST'])\n",
        "def index():\n",
        "    meanings=[]\n",
        "    if request.method == 'POST':\n",
        "        words = request.form['definition'].split()        \n",
        "        idxs = [] \n",
        "        for word in words:\n",
        "          idxs.append(word2idx[word])  \n",
        "        idxs = np.array([0] + idxs + [1]).reshape((1,len(idxs) + 2))\n",
        "        prediction = model.predict(idxs, verbose=0)\n",
        "        ind=np.argpartition(prediction[0],-10)[-10:]\n",
        "        for i in ind[::-1]:\n",
        "          meanings.append(idx2word[i])\n",
        "\n",
        "        return jsonify(meanings)        \n",
        "    else:\n",
        "        #return \"<h1>Running Flask on Google Colab!</h1>\"\n",
        "        return render_template('indexMS.html')\n",
        "\n",
        "\n",
        "run_with_ngrok(app) \n",
        "app.run()\n",
        "\n",
        "        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://c5acacd69b3a.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [07/Dec/2020 06:02:32] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [07/Dec/2020 06:02:32] \"\u001b[37mGET /static/css/bulma/bulma.min.css HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [07/Dec/2020 06:02:32] \"\u001b[37mGET /static/js/jquery-3.3.1.min.js HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [07/Dec/2020 06:02:33] \"\u001b[37mGET /static/js/main.js HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [07/Dec/2020 06:02:50] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "[2020-12-07 06:02:53,417] ERROR in app: Exception on / [POST]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 2447, in wsgi_app\n",
            "    response = self.full_dispatch_request()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1952, in full_dispatch_request\n",
            "    rv = self.handle_user_exception(e)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1821, in handle_user_exception\n",
            "    reraise(exc_type, exc_value, tb)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/_compat.py\", line 39, in reraise\n",
            "    raise value\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1950, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1936, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"<ipython-input-9-f822280771f0>\", line 17, in index\n",
            "    prediction = model.predict(idxs, verbose=0)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 130, in _method_wrapper\n",
            "    return method(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 1599, in predict\n",
            "    tmp_batch_outputs = predict_function(iterator)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 780, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 814, in _call\n",
            "    results = self._stateful_fn(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 2829, in __call__\n",
            "    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1848, in _filtered_call\n",
            "    cancellation_manager=cancellation_manager)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1924, in _call_flat\n",
            "    ctx, args, cancellation_manager=cancellation_manager))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 550, in call\n",
            "    ctx=ctx)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\n",
            "    inputs, attrs, num_outputs)\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError:  Input to reshape is a tensor with 21504 values, but the requested shape has 30720\n",
            "\t [[node functional_3/ms_embedding_1/Reshape (defined at /content/ms_embedding.py:118) ]] [Op:__inference_predict_function_35055]\n",
            "\n",
            "Errors may have originated from an input operation.\n",
            "Input Source operations connected to node functional_3/ms_embedding_1/Reshape:\n",
            " functional_3/ms_embedding_1/Tile (defined at /content/ms_embedding.py:117)\n",
            "\n",
            "Function call stack:\n",
            "predict_function\n",
            "\n",
            "127.0.0.1 - - [07/Dec/2020 06:02:53] \"\u001b[35m\u001b[1mPOST / HTTP/1.1\u001b[0m\" 500 -\n",
            "[2020-12-07 06:02:55,421] ERROR in app: Exception on / [POST]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 2447, in wsgi_app\n",
            "    response = self.full_dispatch_request()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1952, in full_dispatch_request\n",
            "    rv = self.handle_user_exception(e)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1821, in handle_user_exception\n",
            "    reraise(exc_type, exc_value, tb)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/_compat.py\", line 39, in reraise\n",
            "    raise value\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1950, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1936, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"<ipython-input-9-f822280771f0>\", line 17, in index\n",
            "    prediction = model.predict(idxs, verbose=0)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 130, in _method_wrapper\n",
            "    return method(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 1599, in predict\n",
            "    tmp_batch_outputs = predict_function(iterator)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 780, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 814, in _call\n",
            "    results = self._stateful_fn(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 2829, in __call__\n",
            "    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1848, in _filtered_call\n",
            "    cancellation_manager=cancellation_manager)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1924, in _call_flat\n",
            "    ctx, args, cancellation_manager=cancellation_manager))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 550, in call\n",
            "    ctx=ctx)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\n",
            "    inputs, attrs, num_outputs)\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError:  Input to reshape is a tensor with 21504 values, but the requested shape has 30720\n",
            "\t [[node functional_3/ms_embedding_1/Reshape (defined at /content/ms_embedding.py:118) ]] [Op:__inference_predict_function_35055]\n",
            "\n",
            "Errors may have originated from an input operation.\n",
            "Input Source operations connected to node functional_3/ms_embedding_1/Reshape:\n",
            " functional_3/ms_embedding_1/Tile (defined at /content/ms_embedding.py:117)\n",
            "\n",
            "Function call stack:\n",
            "predict_function\n",
            "\n",
            "127.0.0.1 - - [07/Dec/2020 06:02:55] \"\u001b[35m\u001b[1mPOST / HTTP/1.1\u001b[0m\" 500 -\n",
            "[2020-12-07 06:03:20,642] ERROR in app: Exception on / [POST]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 2447, in wsgi_app\n",
            "    response = self.full_dispatch_request()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1952, in full_dispatch_request\n",
            "    rv = self.handle_user_exception(e)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1821, in handle_user_exception\n",
            "    reraise(exc_type, exc_value, tb)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/_compat.py\", line 39, in reraise\n",
            "    raise value\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1950, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1936, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"<ipython-input-9-f822280771f0>\", line 17, in index\n",
            "    prediction = model.predict(idxs, verbose=0)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 130, in _method_wrapper\n",
            "    return method(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 1599, in predict\n",
            "    tmp_batch_outputs = predict_function(iterator)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 780, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 814, in _call\n",
            "    results = self._stateful_fn(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 2829, in __call__\n",
            "    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1848, in _filtered_call\n",
            "    cancellation_manager=cancellation_manager)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1924, in _call_flat\n",
            "    ctx, args, cancellation_manager=cancellation_manager))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 550, in call\n",
            "    ctx=ctx)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\n",
            "    inputs, attrs, num_outputs)\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError:  Input to reshape is a tensor with 33792 values, but the requested shape has 30720\n",
            "\t [[node functional_3/ms_embedding_1/Reshape (defined at /content/ms_embedding.py:118) ]] [Op:__inference_predict_function_35055]\n",
            "\n",
            "Errors may have originated from an input operation.\n",
            "Input Source operations connected to node functional_3/ms_embedding_1/Reshape:\n",
            " functional_3/ms_embedding_1/Tile (defined at /content/ms_embedding.py:117)\n",
            "\n",
            "Function call stack:\n",
            "predict_function\n",
            "\n",
            "127.0.0.1 - - [07/Dec/2020 06:03:20] \"\u001b[35m\u001b[1mPOST / HTTP/1.1\u001b[0m\" 500 -\n",
            "[2020-12-07 06:03:22,437] ERROR in app: Exception on / [POST]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 2447, in wsgi_app\n",
            "    response = self.full_dispatch_request()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1952, in full_dispatch_request\n",
            "    rv = self.handle_user_exception(e)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1821, in handle_user_exception\n",
            "    reraise(exc_type, exc_value, tb)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/_compat.py\", line 39, in reraise\n",
            "    raise value\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1950, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1936, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"<ipython-input-9-f822280771f0>\", line 17, in index\n",
            "    prediction = model.predict(idxs, verbose=0)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 130, in _method_wrapper\n",
            "    return method(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 1599, in predict\n",
            "    tmp_batch_outputs = predict_function(iterator)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 780, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 814, in _call\n",
            "    results = self._stateful_fn(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 2829, in __call__\n",
            "    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1848, in _filtered_call\n",
            "    cancellation_manager=cancellation_manager)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1924, in _call_flat\n",
            "    ctx, args, cancellation_manager=cancellation_manager))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 550, in call\n",
            "    ctx=ctx)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\n",
            "    inputs, attrs, num_outputs)\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError:  Input to reshape is a tensor with 33792 values, but the requested shape has 30720\n",
            "\t [[node functional_3/ms_embedding_1/Reshape (defined at /content/ms_embedding.py:118) ]] [Op:__inference_predict_function_35055]\n",
            "\n",
            "Errors may have originated from an input operation.\n",
            "Input Source operations connected to node functional_3/ms_embedding_1/Reshape:\n",
            " functional_3/ms_embedding_1/Tile (defined at /content/ms_embedding.py:117)\n",
            "\n",
            "Function call stack:\n",
            "predict_function\n",
            "\n",
            "127.0.0.1 - - [07/Dec/2020 06:03:22] \"\u001b[35m\u001b[1mPOST / HTTP/1.1\u001b[0m\" 500 -\n",
            "[2020-12-07 06:04:18,267] ERROR in app: Exception on / [POST]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 2447, in wsgi_app\n",
            "    response = self.full_dispatch_request()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1952, in full_dispatch_request\n",
            "    rv = self.handle_user_exception(e)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1821, in handle_user_exception\n",
            "    reraise(exc_type, exc_value, tb)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/_compat.py\", line 39, in reraise\n",
            "    raise value\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1950, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1936, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"<ipython-input-9-f822280771f0>\", line 17, in index\n",
            "    prediction = model.predict(idxs, verbose=0)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 130, in _method_wrapper\n",
            "    return method(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 1599, in predict\n",
            "    tmp_batch_outputs = predict_function(iterator)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 780, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 814, in _call\n",
            "    results = self._stateful_fn(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 2829, in __call__\n",
            "    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1848, in _filtered_call\n",
            "    cancellation_manager=cancellation_manager)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1924, in _call_flat\n",
            "    ctx, args, cancellation_manager=cancellation_manager))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 550, in call\n",
            "    ctx=ctx)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\n",
            "    inputs, attrs, num_outputs)\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError:  Input to reshape is a tensor with 16896 values, but the requested shape has 30720\n",
            "\t [[node functional_3/ms_embedding_1/Reshape (defined at /content/ms_embedding.py:118) ]] [Op:__inference_predict_function_35055]\n",
            "\n",
            "Errors may have originated from an input operation.\n",
            "Input Source operations connected to node functional_3/ms_embedding_1/Reshape:\n",
            " functional_3/ms_embedding_1/Tile (defined at /content/ms_embedding.py:117)\n",
            "\n",
            "Function call stack:\n",
            "predict_function\n",
            "\n",
            "127.0.0.1 - - [07/Dec/2020 06:04:18] \"\u001b[35m\u001b[1mPOST / HTTP/1.1\u001b[0m\" 500 -\n",
            "[2020-12-07 06:04:20,226] ERROR in app: Exception on / [POST]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 2447, in wsgi_app\n",
            "    response = self.full_dispatch_request()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1952, in full_dispatch_request\n",
            "    rv = self.handle_user_exception(e)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1821, in handle_user_exception\n",
            "    reraise(exc_type, exc_value, tb)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/_compat.py\", line 39, in reraise\n",
            "    raise value\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1950, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1936, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"<ipython-input-9-f822280771f0>\", line 17, in index\n",
            "    prediction = model.predict(idxs, verbose=0)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 130, in _method_wrapper\n",
            "    return method(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 1599, in predict\n",
            "    tmp_batch_outputs = predict_function(iterator)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 780, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 814, in _call\n",
            "    results = self._stateful_fn(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 2829, in __call__\n",
            "    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1848, in _filtered_call\n",
            "    cancellation_manager=cancellation_manager)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1924, in _call_flat\n",
            "    ctx, args, cancellation_manager=cancellation_manager))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 550, in call\n",
            "    ctx=ctx)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\n",
            "    inputs, attrs, num_outputs)\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError:  Input to reshape is a tensor with 16896 values, but the requested shape has 30720\n",
            "\t [[node functional_3/ms_embedding_1/Reshape (defined at /content/ms_embedding.py:118) ]] [Op:__inference_predict_function_35055]\n",
            "\n",
            "Errors may have originated from an input operation.\n",
            "Input Source operations connected to node functional_3/ms_embedding_1/Reshape:\n",
            " functional_3/ms_embedding_1/Tile (defined at /content/ms_embedding.py:117)\n",
            "\n",
            "Function call stack:\n",
            "predict_function\n",
            "\n",
            "127.0.0.1 - - [07/Dec/2020 06:04:20] \"\u001b[35m\u001b[1mPOST / HTTP/1.1\u001b[0m\" 500 -\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}